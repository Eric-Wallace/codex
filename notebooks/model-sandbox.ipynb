{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1f506b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/private/home/dpf/projects/codex\n"
     ]
    }
   ],
   "source": [
    "cd /private/home/dpf/projects/codex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb03399c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45aba1b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/private/home/dpf/projects/codex/notebooks',\n",
       " '/private/home/dpf/.conda/envs/fairseq-20210318-htlm_2/lib/python38.zip',\n",
       " '/private/home/dpf/.conda/envs/fairseq-20210318-htlm_2/lib/python3.8',\n",
       " '/private/home/dpf/.conda/envs/fairseq-20210318-htlm_2/lib/python3.8/lib-dynload',\n",
       " '',\n",
       " '/private/home/dpf/.local/lib/python3.8/site-packages',\n",
       " '/private/home/dpf/.conda/envs/fairseq-20210318-htlm_2/lib/python3.8/site-packages',\n",
       " '/private/home/dpf/projects/Megatron-LM',\n",
       " '/private/home/dpf/projects/htlm_2/fairseq-py',\n",
       " '/private/home/dpf/projects/tokenizers/bindings/python/py_src',\n",
       " '/private/home/dpf/projects/human-eval',\n",
       " '/private/home/dpf/.conda/envs/fairseq-20210318-htlm_2/lib/python3.8/site-packages/IPython/extensions',\n",
       " '/private/home/dpf/.ipython']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19bffe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f390aa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b0f76e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from he import make_parser, HUMAN_EVAL_STOP_WORDS\n",
    "import shlex\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e193a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89f31738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fairseq.models.bart import BARTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf0f4b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bart_model = BARTModel.from_pretrained(\n",
    "#     \"/checkpoint/dpf/2022-03-10/ours.bart.pytorch-ddp-bs2.old-init.bart_1B.tps2048.uf4.mu49591.ms2.dr0.1.atdr0.1.actdr0.0.wd0.01.adam.beta9999.eps1e-08.clip1.0.lr0.0002.warm1500.fp16.poi_lam3.5.mask0.3.mask_lenspan-poisson.rpl_len1.rotate0.mask_rand0.1.ins0.perm_sen0.0.ngpu64\",\n",
    "#     \"checkpoint_1_9000.pt\",\n",
    "#     \"/checkpoint/dpf/2022-03-10/ours.bart.pytorch-ddp-bs2.old-init.bart_1B.tps2048.uf4.mu49591.ms2.dr0.1.atdr0.1.actdr0.0.wd0.01.adam.beta9999.eps1e-08.clip1.0.lr0.0002.warm1500.fp16.poi_lam3.5.mask0.3.mask_lenspan-poisson.rpl_len1.rotate0.mask_rand0.1.ins0.perm_sen0.0.ngpu64\",\n",
    "#     bpe=\"gpt2_pretokenization_newlines_only\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e01944b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded = bart_model.encode(\"def count_words(filename):\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d45586bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "644610c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = make_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2487df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args(shlex.split(\"--model_name /checkpoint/dpf/models/cm-6B-armen/checkpoint_last_consolidated.pt --num_candidates_generated 1 --num_candidates_evaluated 1 --batch_size 3 --temperature 0.2 --top_p 0.95 --output_filename expts/he/lm-1.3B-ourtok_last_ncg-1_temp-0.2/prompt_pyfile_normalized/samples.jsonl --response_filename expts/he/lm-1.3B-ourtok_last_ncg-1_temp-0.2/prompt_pyfile_normalized/responses.pkl --prompt_prefix '<| file ext=.py |>' --tokenizer_name gpt2_pretokenization_newlines_only\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d54f5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 3,\n",
      " 'beam': 1,\n",
      " 'cached_responses': False,\n",
      " 'candidate_scoring': 'mean',\n",
      " 'git_status': False,\n",
      " 'max_tokens': 450,\n",
      " 'model_name': '/checkpoint/dpf/models/cm-6B-armen/checkpoint_last_consolidated.pt',\n",
      " 'multiple_cached_responses_filenames': None,\n",
      " 'num_candidates_evaluated': 1,\n",
      " 'num_candidates_generated': 1,\n",
      " 'num_problems': None,\n",
      " 'output_filename': 'expts/he/lm-1.3B-ourtok_last_ncg-1_temp-0.2/prompt_pyfile_normalized/samples.jsonl',\n",
      " 'prompt_prefix': '<| file ext=.py |>',\n",
      " 'remove_test_cases': False,\n",
      " 'response_filename': 'expts/he/lm-1.3B-ourtok_last_ncg-1_temp-0.2/prompt_pyfile_normalized/responses.pkl',\n",
      " 'temperature': 0.2,\n",
      " 'tokenizer_name': 'gpt2_pretokenization_newlines_only',\n",
      " 'top_p': 0.95,\n",
      " 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6b5645d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Pytorch pre-release version 1.8.0a0+37c1f4a - assuming intent to test it\n",
      "WARNING:root:Torch AMP is not available on this platform\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_root_dir: /checkpoint/dpf/models/cm-6B-armen\n",
      "model_basename: checkpoint_last_consolidated.pt\n",
      "dictionary size: 50518\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /private/home/dpf/projects/Megatron-LM/megatron/fused_kernels/build/build.ninja...\n",
      "Building extension module fused_mix_prec_layer_norm_cuda...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module fused_mix_prec_layer_norm_cuda...\n"
     ]
    }
   ],
   "source": [
    "model = make_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3a17aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sentinel:2>', 'importÄ re']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[model.tokenizer.id_to_token(id-4) for id in model._encode(\"<sentinel:2>import re\", strip_eos=True).tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b604caf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path[0] = '/private/home/dpf/projects/codex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1284c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from human_eval.data import read_problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b41732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = list(sorted(read_problems().items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ddb96d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_id, problem = problems[0]\n",
    "prompt = problem['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "934c8f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32631eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.num_candidates_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77e046c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "pdb on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00ce5398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_root_dir: /checkpoint/dpf/models/cm-6B-armen\n",
      "model_basename: checkpoint_last_consolidated.pt\n"
     ]
    }
   ],
   "source": [
    "model = make_model(args, cached_model=model.lm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e69259e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/home/dpf/projects/codex/models.py:620: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  token_ids = torch.tensor(tokens)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'choices': [{'text': '    smallest_value = numbers[0]\\n    second_smallest_value = numbers[1]\\n    for number in numbers:\\n        if abs(number - smallest_value) < abs(number - second_smallest_value):\\n            second_smallest_value = smallest_value\\n            smallest_value = number\\n        else:\\n            second_smallest_value = number\\n    return abs(smallest_value - threshold) < abs(second_smallest_value - threshold)\\n\\n',\n",
       "   'logprobs': {'token_logprobs': [0.6997772455215454,\n",
       "     0.016930216923356056,\n",
       "     0.703140139579773,\n",
       "     0.04975461587309837,\n",
       "     0.3273661434650421,\n",
       "     0.9991055727005005,\n",
       "     0.9880794286727905,\n",
       "     0.9564300179481506,\n",
       "     0.6541919708251953,\n",
       "     0.9918103218078613,\n",
       "     0.9797477722167969,\n",
       "     0.9973158836364746,\n",
       "     0.9965722560882568,\n",
       "     0.6786525845527649,\n",
       "     0.7235873937606812,\n",
       "     0.7021003365516663,\n",
       "     0.5949846506118774,\n",
       "     0.9999898672103882,\n",
       "     0.999866783618927,\n",
       "     0.937919557094574,\n",
       "     0.9999516010284424,\n",
       "     0.9869207143783569,\n",
       "     0.6107980012893677,\n",
       "     0.95079106092453,\n",
       "     0.9999927878379822,\n",
       "     0.877011239528656,\n",
       "     1.0,\n",
       "     0.9993632435798645,\n",
       "     0.9141995310783386,\n",
       "     0.48583856225013733,\n",
       "     0.6010461449623108,\n",
       "     0.9999537467956543,\n",
       "     0.9999955892562866,\n",
       "     0.9999993443489075,\n",
       "     1.0,\n",
       "     0.9984891414642334,\n",
       "     0.9999555945396423,\n",
       "     0.9714283347129822,\n",
       "     0.9017124772071838,\n",
       "     0.9999986886978149,\n",
       "     1.0,\n",
       "     0.9999200701713562,\n",
       "     0.9630666971206665,\n",
       "     1.0,\n",
       "     0.9996669292449951,\n",
       "     0.9991041421890259,\n",
       "     0.9576964378356934,\n",
       "     0.999981164932251,\n",
       "     1.0,\n",
       "     0.9999747276306152,\n",
       "     0.9999865889549255,\n",
       "     0.9991679191589355,\n",
       "     0.6528323292732239,\n",
       "     0.9999740123748779,\n",
       "     0.9883702993392944,\n",
       "     0.92610102891922,\n",
       "     0.9999973773956299,\n",
       "     0.9999998807907104,\n",
       "     0.9999456405639648,\n",
       "     0.7154530882835388,\n",
       "     0.9739784598350525,\n",
       "     0.8387720584869385,\n",
       "     0.32209447026252747,\n",
       "     0.8282940983772278,\n",
       "     1.0,\n",
       "     0.9940294027328491,\n",
       "     0.5800427198410034,\n",
       "     0.9793917536735535,\n",
       "     0.9996249079704285,\n",
       "     0.9814077019691467,\n",
       "     0.9999822974205017,\n",
       "     1.0,\n",
       "     0.9991843104362488,\n",
       "     0.9990596771240234,\n",
       "     0.996249258518219],\n",
       "    'tokens': ['    ',\n",
       "     'smalle',\n",
       "     'st_',\n",
       "     'value = ',\n",
       "     'number',\n",
       "     's[0]',\n",
       "     '\\n',\n",
       "     '    ',\n",
       "     'second_',\n",
       "     'smalle',\n",
       "     'st_',\n",
       "     'value = ',\n",
       "     'number',\n",
       "     's[1]',\n",
       "     '\\n',\n",
       "     '    for ',\n",
       "     'number ',\n",
       "     'in ',\n",
       "     'number',\n",
       "     's:',\n",
       "     '\\n',\n",
       "     '        if ',\n",
       "     'abs(',\n",
       "     'number ',\n",
       "     '- ',\n",
       "     'smalle',\n",
       "     'st_',\n",
       "     'value',\n",
       "     ') < ',\n",
       "     'abs(',\n",
       "     'number ',\n",
       "     '- ',\n",
       "     'second_',\n",
       "     'smalle',\n",
       "     'st_',\n",
       "     'value):',\n",
       "     '\\n',\n",
       "     '            ',\n",
       "     'second_',\n",
       "     'smalle',\n",
       "     'st_',\n",
       "     'value = ',\n",
       "     'smalle',\n",
       "     'st_',\n",
       "     'value',\n",
       "     '\\n',\n",
       "     '            ',\n",
       "     'smalle',\n",
       "     'st_',\n",
       "     'value = ',\n",
       "     'number',\n",
       "     '\\n',\n",
       "     '        else:',\n",
       "     '\\n',\n",
       "     '            ',\n",
       "     'second_',\n",
       "     'smalle',\n",
       "     'st_',\n",
       "     'value = ',\n",
       "     'number',\n",
       "     '\\n',\n",
       "     '    return ',\n",
       "     'abs(',\n",
       "     'smalle',\n",
       "     'st_',\n",
       "     'value - ',\n",
       "     'threshold',\n",
       "     ') < ',\n",
       "     'abs(',\n",
       "     'second_',\n",
       "     'smalle',\n",
       "     'st_',\n",
       "     'value - ',\n",
       "     'threshold)',\n",
       "     '\\n\\n']}},\n",
       "  {'text': '    if len(numbers) < 2:\\n        return True\\n\\n    numbers.sort()\\n    difference = threshold\\n\\n    for index, value in enumerate(numbers):\\n        if index + 1 < len(numbers):\\n            next_value = numbers[index + 1]\\n            difference = abs(value - next_value)\\n        else:\\n            difference = abs(value - numbers[0])\\n\\n        if difference < difference:\\n            return True\\n\\n    return False\\n\\n',\n",
       "   'logprobs': {'token_logprobs': [0.1335548460483551,\n",
       "     0.9997603297233582,\n",
       "     0.9317648410797119,\n",
       "     0.9293438196182251,\n",
       "     0.999737560749054,\n",
       "     0.24855774641036987,\n",
       "     0.46789151430130005,\n",
       "     0.8557835221290588,\n",
       "     0.47254326939582825,\n",
       "     0.9824355840682983,\n",
       "     0.6715832352638245,\n",
       "     0.8604944348335266,\n",
       "     0.0455012321472168,\n",
       "     0.42125996947288513,\n",
       "     0.0715160220861435,\n",
       "     0.24668487906455994,\n",
       "     0.5263715386390686,\n",
       "     0.21320617198944092,\n",
       "     0.10028385370969772,\n",
       "     0.9999376535415649,\n",
       "     0.9998730421066284,\n",
       "     0.9183841943740845,\n",
       "     0.9976649284362793,\n",
       "     0.7991644144058228,\n",
       "     0.13513119518756866,\n",
       "     0.7962452173233032,\n",
       "     0.9999836087226868,\n",
       "     0.9988619089126587,\n",
       "     0.7551274299621582,\n",
       "     0.9995782971382141,\n",
       "     0.12082263082265854,\n",
       "     0.9692611694335938,\n",
       "     0.999941349029541,\n",
       "     0.9997673630714417,\n",
       "     0.9994462728500366,\n",
       "     0.9097031354904175,\n",
       "     0.19435161352157593,\n",
       "     0.5239613056182861,\n",
       "     0.8217588067054749,\n",
       "     0.7857100367546082,\n",
       "     0.957925021648407,\n",
       "     0.9997080564498901,\n",
       "     0.9930902123451233,\n",
       "     0.4843710660934448,\n",
       "     0.2937248945236206,\n",
       "     0.9995947480201721,\n",
       "     0.7382456660270691,\n",
       "     0.9987587332725525,\n",
       "     0.9425114989280701,\n",
       "     0.9754192233085632,\n",
       "     0.9787887930870056,\n",
       "     0.4340510368347168,\n",
       "     0.9663155674934387,\n",
       "     0.9603173136711121,\n",
       "     0.9957303404808044,\n",
       "     0.9981566071510315,\n",
       "     0.7511281371116638,\n",
       "     0.6956100463867188,\n",
       "     0.9974029660224915,\n",
       "     0.9999982118606567,\n",
       "     0.846713662147522,\n",
       "     0.9356423020362854,\n",
       "     0.999584436416626,\n",
       "     0.9990629553794861],\n",
       "    'tokens': ['    if len(',\n",
       "     'number',\n",
       "     's) < ',\n",
       "     '2:',\n",
       "     '\\n',\n",
       "     '        return True',\n",
       "     '\\n\\n',\n",
       "     '    ',\n",
       "     'numbers.',\n",
       "     'sort()',\n",
       "     '\\n',\n",
       "     '    ',\n",
       "     'difference',\n",
       "     ' = ',\n",
       "     'threshold',\n",
       "     '\\n\\n',\n",
       "     '    for ',\n",
       "     'index, ',\n",
       "     'value in ',\n",
       "     'enumerate(',\n",
       "     'number',\n",
       "     's):',\n",
       "     '\\n',\n",
       "     '        if ',\n",
       "     'index + ',\n",
       "     '1 < ',\n",
       "     'len(',\n",
       "     'number',\n",
       "     's):',\n",
       "     '\\n',\n",
       "     '            next_',\n",
       "     'value = ',\n",
       "     'number',\n",
       "     's[index',\n",
       "     ' + 1]',\n",
       "     '\\n',\n",
       "     '            ',\n",
       "     'difference',\n",
       "     ' = ',\n",
       "     'abs(',\n",
       "     'value - ',\n",
       "     'next_',\n",
       "     'value)',\n",
       "     '\\n',\n",
       "     '        else:',\n",
       "     '\\n',\n",
       "     '            ',\n",
       "     'difference',\n",
       "     ' = ',\n",
       "     'abs(',\n",
       "     'value - ',\n",
       "     'number',\n",
       "     's[0])',\n",
       "     '\\n\\n',\n",
       "     '        if ',\n",
       "     'difference ',\n",
       "     '< ',\n",
       "     'difference',\n",
       "     ':',\n",
       "     '\\n',\n",
       "     '            return True',\n",
       "     '\\n\\n',\n",
       "     '    return False',\n",
       "     '\\n\\n']}},\n",
       "  {'text': '    \\n    length = len(numbers)\\n    if length < 2:\\n        return False\\n    \\n    last = 0\\n    for i in range(length - 1):\\n        if numbers[i] > numbers[last]:\\n            last = i\\n    \\n    distance = abs(numbers[last] - threshold)\\n    if last == length - 1:\\n        return True\\n    else:\\n        return distance < abs(numbers[last + 1] - threshold)\\n\\n',\n",
       "   'logprobs': {'token_logprobs': [0.6997773051261902,\n",
       "     0.004348039627075195,\n",
       "     0.5327496528625488,\n",
       "     0.21453197300434113,\n",
       "     0.9965072870254517,\n",
       "     0.9993972778320312,\n",
       "     0.9685710668563843,\n",
       "     0.2914593517780304,\n",
       "     0.8467806577682495,\n",
       "     0.8478307127952576,\n",
       "     0.9542980790138245,\n",
       "     0.9998740553855896,\n",
       "     0.6429603099822998,\n",
       "     0.7981023788452148,\n",
       "     0.9584367871284485,\n",
       "     0.9960749745368958,\n",
       "     0.7443706393241882,\n",
       "     0.0015434585511684418,\n",
       "     0.33851948380470276,\n",
       "     0.9981361627578735,\n",
       "     0.3755888342857361,\n",
       "     0.22499679028987885,\n",
       "     0.9928614497184753,\n",
       "     0.9997937083244324,\n",
       "     0.6647541522979736,\n",
       "     0.38316529989242554,\n",
       "     0.8582226037979126,\n",
       "     0.9057934880256653,\n",
       "     0.9593808054924011,\n",
       "     0.8478266000747681,\n",
       "     0.980475127696991,\n",
       "     0.6221083402633667,\n",
       "     0.9998471140861511,\n",
       "     0.21114587783813477,\n",
       "     0.9999725818634033,\n",
       "     0.997821569442749,\n",
       "     0.9849992394447327,\n",
       "     0.29228657484054565,\n",
       "     0.9989048838615417,\n",
       "     0.24872654676437378,\n",
       "     0.0026977669913321733,\n",
       "     0.9114245772361755,\n",
       "     0.7473919987678528,\n",
       "     0.993671178817749,\n",
       "     0.9795606136322021,\n",
       "     0.99905925989151,\n",
       "     0.7987210750579834,\n",
       "     0.9940493106842041,\n",
       "     0.05827762931585312,\n",
       "     0.6107973456382751,\n",
       "     0.285508394241333,\n",
       "     0.8647230863571167,\n",
       "     0.45240485668182373,\n",
       "     0.9997375011444092,\n",
       "     0.8127541542053223,\n",
       "     0.9936031103134155,\n",
       "     0.18597929179668427,\n",
       "     0.9999209642410278,\n",
       "     0.7348242402076721,\n",
       "     0.6894847750663757,\n",
       "     0.9200533628463745,\n",
       "     0.9995271563529968,\n",
       "     0.9997870922088623,\n",
       "     0.9999147653579712,\n",
       "     0.9511014819145203,\n",
       "     0.9740391373634338,\n",
       "     0.9999954700469971,\n",
       "     0.9998732805252075,\n",
       "     0.9463422894477844,\n",
       "     0.9454091787338257],\n",
       "    'tokens': ['    ',\n",
       "     '\\n',\n",
       "     '    ',\n",
       "     'length = len(',\n",
       "     'number',\n",
       "     's)',\n",
       "     '\\n',\n",
       "     '    if ',\n",
       "     'length',\n",
       "     ' < ',\n",
       "     '2:',\n",
       "     '\\n',\n",
       "     '        return False',\n",
       "     '\\n',\n",
       "     '    ',\n",
       "     '\\n',\n",
       "     '    ',\n",
       "     'last',\n",
       "     ' = 0',\n",
       "     '\\n',\n",
       "     '    for i in range(',\n",
       "     'length - ',\n",
       "     '1):',\n",
       "     '\\n',\n",
       "     '        if ',\n",
       "     'number',\n",
       "     's[i',\n",
       "     '] > ',\n",
       "     'number',\n",
       "     's[',\n",
       "     'last',\n",
       "     ']:',\n",
       "     '\\n',\n",
       "     '            last',\n",
       "     ' = ',\n",
       "     'i',\n",
       "     '\\n',\n",
       "     '    ',\n",
       "     '\\n',\n",
       "     '    ',\n",
       "     'distance = ',\n",
       "     'abs(',\n",
       "     'number',\n",
       "     's[',\n",
       "     'last',\n",
       "     '] - ',\n",
       "     'threshold)',\n",
       "     '\\n',\n",
       "     '    if ',\n",
       "     'last ',\n",
       "     '== ',\n",
       "     'length - ',\n",
       "     '1:',\n",
       "     '\\n',\n",
       "     '        return True',\n",
       "     '\\n',\n",
       "     '    else:',\n",
       "     '\\n',\n",
       "     '        return ',\n",
       "     'distance ',\n",
       "     '< ',\n",
       "     'abs(',\n",
       "     'number',\n",
       "     's[',\n",
       "     'last ',\n",
       "     '+ ',\n",
       "     '1]',\n",
       "     ' - ',\n",
       "     'threshold)',\n",
       "     '\\n\\n']}},\n",
       "  {'text': '    length = len(numbers)\\n    for i in range(length):\\n        for j in range(i + 1, length):\\n            if abs(numbers[i] - numbers[j]) < threshold:\\n                return True\\n    return False\\n\\n',\n",
       "   'logprobs': {'token_logprobs': [0.6997772455215454,\n",
       "     0.32959020137786865,\n",
       "     0.9960479140281677,\n",
       "     0.9998955726623535,\n",
       "     0.9657367467880249,\n",
       "     0.24373532831668854,\n",
       "     0.449207603931427,\n",
       "     0.9996087551116943,\n",
       "     0.8865931630134583,\n",
       "     0.5398344397544861,\n",
       "     0.9996315836906433,\n",
       "     0.999763011932373,\n",
       "     0.9997479915618896,\n",
       "     0.905890166759491,\n",
       "     0.9514018893241882,\n",
       "     0.9992766976356506,\n",
       "     0.960954487323761,\n",
       "     1.0,\n",
       "     1.0,\n",
       "     0.9615251421928406,\n",
       "     0.7976891398429871,\n",
       "     0.999782383441925,\n",
       "     0.9999721050262451,\n",
       "     0.9999992847442627,\n",
       "     0.9986724853515625,\n",
       "     0.968435525894165,\n",
       "     0.9996594190597534,\n",
       "     0.9993168115615845],\n",
       "    'tokens': ['    ',\n",
       "     'length = len(',\n",
       "     'number',\n",
       "     's)',\n",
       "     '\\n',\n",
       "     '    for i in range(',\n",
       "     'length):',\n",
       "     '\\n',\n",
       "     '        for j in range(',\n",
       "     'i + ',\n",
       "     '1, ',\n",
       "     'length):',\n",
       "     '\\n',\n",
       "     '            if ',\n",
       "     'abs(',\n",
       "     'number',\n",
       "     's[i',\n",
       "     '] - ',\n",
       "     'number',\n",
       "     's[j]',\n",
       "     ') < ',\n",
       "     'threshold',\n",
       "     ':',\n",
       "     '\\n',\n",
       "     '                return True',\n",
       "     '\\n',\n",
       "     '    return False',\n",
       "     '\\n\\n']}},\n",
       "  {'text': '    if len(numbers) <= 1:\\n        return True\\n\\n    numbers.sort()\\n    previous_number = numbers[0]\\n    for number in numbers[1:]:\\n        if abs(number - previous_number) < threshold:\\n            return True\\n        previous_number = number\\n\\n    return False\\n\\n',\n",
       "   'logprobs': {'token_logprobs': [0.1335548460483551,\n",
       "     0.9997603297233582,\n",
       "     0.03845852613449097,\n",
       "     0.996385931968689,\n",
       "     0.859821617603302,\n",
       "     0.9997541904449463,\n",
       "     0.5049939751625061,\n",
       "     0.5073558688163757,\n",
       "     0.8692617416381836,\n",
       "     0.3933210074901581,\n",
       "     0.9745522737503052,\n",
       "     0.671690821647644,\n",
       "     0.8838421106338501,\n",
       "     0.04860522598028183,\n",
       "     0.28091299533843994,\n",
       "     0.9837573170661926,\n",
       "     0.9712355732917786,\n",
       "     0.9117233753204346,\n",
       "     0.5132635831832886,\n",
       "     0.8813820481300354,\n",
       "     0.9999962449073792,\n",
       "     0.9999704360961914,\n",
       "     0.7878230810165405,\n",
       "     0.9999892711639404,\n",
       "     0.999690055847168,\n",
       "     0.9842450022697449,\n",
       "     0.9368684887886047,\n",
       "     0.9046791195869446,\n",
       "     0.9999982714653015,\n",
       "     0.9999733567237854,\n",
       "     0.9985784292221069,\n",
       "     0.5771543979644775,\n",
       "     0.9990811347961426,\n",
       "     0.9999372959136963,\n",
       "     0.9999991059303284,\n",
       "     0.951059103012085,\n",
       "     0.9510343074798584,\n",
       "     0.9189184308052063,\n",
       "     0.9999992847442627,\n",
       "     0.9999971389770508,\n",
       "     0.9999947547912598,\n",
       "     0.672134518623352,\n",
       "     0.9995041489601135,\n",
       "     0.9989516735076904],\n",
       "    'tokens': ['    if len(',\n",
       "     'number',\n",
       "     's) ',\n",
       "     '<= ',\n",
       "     '1:',\n",
       "     '\\n',\n",
       "     '        return True',\n",
       "     '\\n\\n',\n",
       "     '    ',\n",
       "     'numbers.',\n",
       "     'sort()',\n",
       "     '\\n',\n",
       "     '    ',\n",
       "     'previous_',\n",
       "     'number = ',\n",
       "     'number',\n",
       "     's[0]',\n",
       "     '\\n',\n",
       "     '    for ',\n",
       "     'number ',\n",
       "     'in ',\n",
       "     'number',\n",
       "     's[1:',\n",
       "     ']:',\n",
       "     '\\n',\n",
       "     '        if ',\n",
       "     'abs(',\n",
       "     'number ',\n",
       "     '- ',\n",
       "     'previous_',\n",
       "     'number',\n",
       "     ') < ',\n",
       "     'threshold',\n",
       "     ':',\n",
       "     '\\n',\n",
       "     '            return True',\n",
       "     '\\n',\n",
       "     '        ',\n",
       "     'previous_',\n",
       "     'number = ',\n",
       "     'number',\n",
       "     '\\n\\n',\n",
       "     '    return False',\n",
       "     '\\n\\n']}}]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.complete(prompt, stop_words=[\"\\ndef\"], sampling=True, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47ae49e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = torch.zeros(4).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7050b29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths += zeros.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa8079f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2, 2])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "877a2d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = torch.zeros(4).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1a0459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros |= True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efcc9cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(~zeros).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "332421fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from priming_generator import TopPSampling, GreedyDecoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ca05f638",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = TopPSampling(model.lm_model, min_len=10, max_len=128, sampling_topp=0.95, temperature=0.6, show_tqdm=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c1c069aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy = GreedyDecoding(model.lm_model, min_len=10, max_len=128, temperature=1.0, show_tqdm=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "04de133b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_prompt = model._encode('if __name__ == \"__main__\":').to(model.lm_model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "27e8dbc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 43])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mct.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b7f50598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([43], device='cuda:0')"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "042f75e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_stop_words = [model._encode(sw, strip_eos=True).tolist() for sw in model._extra_stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5dfae35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|âââââââââââââââââââââââââââââââââââââââââââââââââââ                                                                                                                                                                   | 30/127 [00:02<00:07, 13.74it/s]\n"
     ]
    }
   ],
   "source": [
    "mct, mctlp, mcl = greedy.decode_multiple_candidates(\n",
    "    # remove eos\n",
    "    encoded_prompt[:-1],\n",
    "    num_candidates=1,\n",
    "    encoded_stop_words = [[decoder.eos]] + encoded_stop_words,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "744425ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 127/127 [00:19<00:00,  6.50it/s]\n"
     ]
    }
   ],
   "source": [
    "mct, mctlp, mcl = decoder.decode_multiple_candidates(\n",
    "    # remove eos\n",
    "    encoded_prompt[:-1],\n",
    "    num_candidates=5,\n",
    "    encoded_stop_words = [[decoder.eos]] + encoded_stop_words,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "6ad60300",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "78947771",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.complete(prompt, HUMAN_EVAL_STOP_WORDS, sampling=True, max_tokens=200, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "64da4a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "    length = len(numbers)\n",
      "    for i in range(length - 1):\n",
      "        if abs(numbers[i] - numbers[i + 1]) < threshold:\n",
      "            return True\n",
      "    return False\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "    length = len(numbers)\n",
      "    if length < 2:\n",
      "        return False\n",
      "\n",
      "    numbers.sort()\n",
      "    for i in range(length-1):\n",
      "        if abs(numbers[i] - numbers[i+1]) > threshold:\n",
      "            return True\n",
      "    return False\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "    length = len(numbers)\n",
      "    if length < 2:\n",
      "        return False\n",
      "\n",
      "    # sort list\n",
      "    numbers.sort()\n",
      "\n",
      "    # check if first two numbers are closer to each other than\n",
      "    # the threshold\n",
      "    if abs(numbers[0] - numbers[1]) < threshold:\n",
      "        return True\n",
      "\n",
      "    # check if next two numbers are closer to each other than\n",
      "    # the threshold\n",
      "    if abs(numbers[1] - numbers[2]) < threshold:\n",
      "        return True\n",
      "\n",
      "    # check if next two numbers are closer to each other than\n",
      "    # the threshold\n",
      "    if abs(numbers[2] - numbers[3]) < threshold:\n",
      "        return True\n",
      "\n",
      "    # check if next two numbers are closer to each other than\n",
      "    # the threshold\n",
      "    if abs(numbers[3] - numbers[4]) < threshold:\n",
      "        return True\n",
      "\n",
      "    return False\n",
      "\n",
      "\n",
      "\n",
      "3\n",
      "    length = len(numbers)\n",
      "    for index in range(length):\n",
      "        delta = numbers[index] - threshold\n",
      "        if abs(delta) > numbers[index]:\n",
      "            return False\n",
      "    return True\n",
      "\n",
      "\n",
      "\n",
      "4\n",
      "    length = len(numbers)\n",
      "    i = 0\n",
      "    while i < length - 1:\n",
      "        difference = abs(numbers[i] - numbers[i + 1])\n",
      "        if difference < threshold:\n",
      "            i += 1\n",
      "        else:\n",
      "            return False\n",
      "    return True\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ix, c in enumerate(response['choices']):\n",
    "    print(ix)\n",
    "    print(c['text'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5fb1e71a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "completions, response = model.rank_completions(\n",
    "    prompt, HUMAN_EVAL_STOP_WORDS,\n",
    "    max_tokens=200,\n",
    "    n=5,\n",
    "    cached_response=None,\n",
    "    scoring='mean',\n",
    "    sampling=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.95,\n",
    "    beam=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "12f808ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.rank_infills?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8d5a04cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.prompt_prefix = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "757c99a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.rank_infills?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fbf33e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e16d18dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "pdb on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5d78c819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_root_dir: /checkpoint/dpf/models/cm-6B-armen\n",
      "model_basename: checkpoint_last_consolidated.pt\n"
     ]
    }
   ],
   "source": [
    "model = make_model(args, cached_model=model.lm_model)\n",
    "model.prompt_prefix = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b8626f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'def count_words(filename):\\n    \"\"\"'\n",
    "suffix = '    \"\"\"\\n    with open(filename) as f:\\n        return Counter(f.read().split())'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3541022b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def count_words(filename):\n",
      "   \"\"\"\n"
     ]
    }
   ],
   "source": [
    "print(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "75efd495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \"\"\"\n",
      "    with open(filename) as f:\n",
      "        return Counter(f.read().split())\n"
     ]
    }
   ],
   "source": [
    "print(suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "967d7494",
   "metadata": {},
   "outputs": [],
   "source": [
    "truncation_parameters = [TruncationParameters(1, suffix)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f8696bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['complete', 'infills_untruncated', 'ids', 'logprobs'])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r['choices'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5b420a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Count the number of words in a file\n"
     ]
    }
   ],
   "source": [
    "print(truncate_num_lines(r['choices'][0]['infills_untruncated'][0], max_num_lines=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "87bca447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def count_words(filename):\n",
      "    \"\"\"<sentinel:0>"
     ]
    }
   ],
   "source": [
    "r = model.infill([prefix, suffix],\n",
    "             truncation_parameters=truncation_parameters,\n",
    "             verbose=True,\n",
    "             sampling=True,\n",
    "             temperature=0.0,\n",
    "             top_p=0.95,\n",
    "             n=1,\n",
    "             max_tokens=40,\n",
    "             beam=1\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "175a0de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def count_words(filename):\n",
      "    \"\"\"\n",
      "    Count the number of words in a file.\n",
      "    \"\"\"\n",
      "    with open(filename) as f:\n",
      "        return len(f.read().split())\n",
      "\n",
      "\n",
      "def count_characters(filename):\n",
      "    \"\"\"\n",
      "    Count the number of characters in a file.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    with open(filename) as f:\n",
      "        return Counter(f.read().split())\n"
     ]
    }
   ],
   "source": [
    "print(''.join(r['choices'][0]['complete']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "62a5afb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def count_words(filename):\n",
      "    \"\"\"<sentinel:0>--prefix:--\n",
      "def count_words(filename):\n",
      "    \"\"\"\n",
      "--infill (truncated):--\n",
      "    Count the number of words in a file.\n",
      "--infill (untruncated):--\n",
      "\n",
      "    Count the number of words in a file.\n",
      "    \"\"\"\n",
      "    with open(filename) as f:\n",
      "        return len(f.read().split())\n",
      "\n",
      "\n",
      "def count_characters(filename):\n",
      "    \"\"\"\n",
      "    Count the number of characters in a file.\n",
      "    \"\"\"\n",
      "\n",
      "--suffix:--\n",
      "    \"\"\"\n",
      "    with open(filename) as f:\n",
      "        return Counter(f.read().split())\n"
     ]
    }
   ],
   "source": [
    "completions, response = model.rank_infills(\n",
    "    [prefix, suffix], \n",
    "    truncation_parameters=truncation_parameters,\n",
    "    verbose=True,\n",
    "    bidirectional_scoring=False,\n",
    "    bidirectional_generation=True,\n",
    "    max_tokens=40,\n",
    "    n=1,\n",
    "    cached_response=None,\n",
    "    scoring='random',\n",
    "    sampling=True,\n",
    "    temperature=0.0,\n",
    "    top_p=0.95,\n",
    "    beam=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7ea4f3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def count_words(filename):\n",
      "    \"\"\"\n",
      "    Count the number of words in a file.\n",
      "    \"\"\"\n",
      "    with open(filename) as f:\n",
      "        return Counter(f.read().split())\n"
     ]
    }
   ],
   "source": [
    "print(completions[0]['complete'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c0578483",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1419960/3152976465.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompletions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'text'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_1419960/3152976465.py\u001b[0m(1)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m----> 1 \u001b[0;31m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompletions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "print(completions[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "05f2ae92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    length = len(numbers)\n",
      "    if length < 2:\n",
      "        return False\n",
      "    i = 0\n",
      "    while i < length - 1:\n",
      "        if abs(numbers[i] - numbers[i + 1]) < threshold:\n",
      "            return True\n",
      "        i += 1\n",
      "    return False\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(completions[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a2fee72",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = torch.tensor([    4,  7003,   914,    35,  9444,     6,   205, 48158,   536,   380,\n",
    "         4732, 14180,  1375,   484,  1726, 14641, 37417,  6342,  8660, 18567,\n",
    "          205,  7749, 13161,   366,  2649,  2433,  1726,   463,   937,  2193,\n",
    "         3510, 34254,  1304,   374,  1222,  2065,  2370, 20711,   205,   264,\n",
    "         2649, 13349,   696,   205,  2296,  4732, 14180,  1375,  8877,  6280,\n",
    "        22672,  1201, 13102, 12444,   205,   264,   690,   205,  2296,  4732,\n",
    "        14180,  1375,  8877,  6280,   845,  3554, 41762,  2409,   546, 41091,\n",
    "          845,   589,  3024,  2644,   205, 28660,   205,   768,   205])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4cd224b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<| file ext=.py |>\n",
      "from typing import List\n",
      "\n",
      "\n",
      "def has_close_elements(numbers: List[float], threshold: float) -> bool:\n",
      "    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\n",
      "    given threshold.\n",
      "    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\n",
      "    False\n",
      "    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n",
      "    True\n",
      "    \"\"\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.lm_model.decode(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a19ee67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<| file ext=.py |>\\nfrom typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a7e4b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': '', 'logprobs': {'token_logprobs': [], 'tokens': []}}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24997efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.lm_model.task.source_dictionary.symbols?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8d34c219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': '', 'logprobs': {'token_logprobs': [], 'tokens': []}}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "33df3354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# completions, response = model.rank_completions(\n",
    "#     prompt, HUMAN_EVAL_STOP_WORDS,\n",
    "#     max_tokens=450,\n",
    "#     n=args.num_candidates_generated,\n",
    "#     cached_response=None,\n",
    "#     scoring=args.candidate_scoring,\n",
    "#     temperature=args.temperature,\n",
    "#     top_p=args.top_p,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "654e8585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': '', 'logprobs': {'token_logprobs': [], 'tokens': []}}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b9bf25d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_id': 'HumanEval/0',\n",
       " 'prompt': 'from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n',\n",
       " 'entry_point': 'has_close_elements',\n",
       " 'canonical_solution': '    for idx, elem in enumerate(numbers):\\n        for idx2, elem2 in enumerate(numbers):\\n            if idx != idx2:\\n                distance = abs(elem - elem2)\\n                if distance < threshold:\\n                    return True\\n\\n    return False\\n',\n",
       " 'test': \"\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'dataset': 'test'\\n}\\n\\n\\ndef check(candidate):\\n    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.3) == True\\n    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.05) == False\\n    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.95) == True\\n    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.8) == False\\n    assert candidate([1.0, 2.0, 3.0, 4.0, 5.0, 2.0], 0.1) == True\\n    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 1.0) == True\\n    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 0.5) == False\\n\\n\"}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ee0ca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairseq.priming_generator import TopPSampling, TopKSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3684dc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_p = TopPSampling(model.lm_model, 128, 256, 0.95, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "750a6c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = TopPSampling(model.lm_model, 128, 256, 0.95, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86e8cdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### INFILLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c34e4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import infill_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50d11722",
   "metadata": {},
   "outputs": [],
   "source": [
    "from he import generate_he_infill_problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b0206c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import TruncationParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a249600",
   "metadata": {},
   "outputs": [],
   "source": [
    "infill_parser = infill_evaluation.make_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b49f5053",
   "metadata": {},
   "outputs": [],
   "source": [
    "infill_args = infill_parser.parse_args(shlex.split(\"--model_name /checkpoint/dpf/models/cm-6B-armen/cm-6B-ourtok/best.pt \\\n",
    "  --tokenizer_name gpt2_pretokenization_newlines_only  \\\n",
    "  --candidate_scoring random \\\n",
    "  --batch_size 10 \\\n",
    "  --eval_type one_line \\\n",
    "  --truncation_heuristics num_lines suffix \\\n",
    "  --temperature 0.2 \\\n",
    "  --num_candidates 1 \\\n",
    "  --bidirectional_generation \\\n",
    "  \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dfd16ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 10,\n",
      " 'beam': 1,\n",
      " 'bidirectional_generation': True,\n",
      " 'bidirectional_scoring': False,\n",
      " 'candidate_scoring': 'random',\n",
      " 'eval_type': 'one_line',\n",
      " 'evaluate_only': False,\n",
      " 'git_status': False,\n",
      " 'max_infill_attempts': 1,\n",
      " 'max_tokens': 450,\n",
      " 'model_name': '/checkpoint/dpf/models/cm-6B-armen/cm-6B-ourtok/best.pt',\n",
      " 'num_candidates': 1,\n",
      " 'prompt_prefix': None,\n",
      " 'result_base_path': None,\n",
      " 'temperature': 0.2,\n",
      " 'tokenizer_name': 'gpt2_pretokenization_newlines_only',\n",
      " 'top_p': 0.95,\n",
      " 'truncation_heuristics': ['num_lines', 'suffix']}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(vars(infill_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "57f79a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "acaa3842",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_root_dir: /checkpoint/dpf/models/cm-6B-armen/cm-6B-ourtok\n",
      "model_basename: best.pt\n"
     ]
    }
   ],
   "source": [
    "# no caching\n",
    "# model = make_model(infill_args)\n",
    "# with caching\n",
    "model = make_model(infill_args, cached_model=model.lm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fe7b403c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<models.CausalMasking at 0x7fb656962940>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "573b62c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from human_eval.data import read_problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c49fd2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "humaneval_problems = read_problems()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1818b1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "infill_problems = generate_he_infill_problems(infill_args, eval_type=\"one_line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8abb5515",
   "metadata": {},
   "outputs": [],
   "source": [
    "infill_problems = list(infill_problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ff345213",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.infill?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a4d85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.infill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c0ab1aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, probs = infill_problems[0]\n",
    "problem = probs[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "21343bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_id': 'HumanEval/0',\n",
       " 'num_before': 3,\n",
       " 'num_after': 4,\n",
       " 'missing_lines': '                distance = abs(elem - elem2)',\n",
       " 'prompt_parts': ['from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n    for idx, elem in enumerate(numbers):\\n        for idx2, elem2 in enumerate(numbers):\\n            if idx != idx2:\\n',\n",
       "  '                if distance < threshold:\\n                    return True\\n\\n    return False'],\n",
       " 'canonical_solution': '    for idx, elem in enumerate(numbers):\\n        for idx2, elem2 in enumerate(numbers):\\n            if idx != idx2:\\n                distance = abs(elem - elem2)\\n                if distance < threshold:\\n                    return True\\n\\n    return False\\n'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1270bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  376,  5003, 23193, 18844,   201])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._encode(\"def count_words(filename):\\n\")[:-1] - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2a51a6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_parts = problem[\"prompt_parts\"]\n",
    "prefix, suffix = prompt_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6913be29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    \"\"\"'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._decode([768])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5ee59aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1918aacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_stop = model.infill(prompt_parts, stop_words=['abs('], max_tokens=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2c209452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['from typing import List',\n",
       " '\\n\\n\\n',\n",
       " 'def ',\n",
       " 'has_',\n",
       " 'close_',\n",
       " 'element',\n",
       " 's(',\n",
       " 'number',\n",
       " 's: List[',\n",
       " 'float], ',\n",
       " 'threshold',\n",
       " ': float',\n",
       " ') -> bool:',\n",
       " '\\n',\n",
       " '    \"\"\" ',\n",
       " 'Check if ',\n",
       " 'in ',\n",
       " 'given ',\n",
       " 'list of ',\n",
       " 'number',\n",
       " 's, ',\n",
       " 'are ',\n",
       " 'any ',\n",
       " 'two ',\n",
       " 'numbers ',\n",
       " 'clo',\n",
       " 'ser',\n",
       " ' to ',\n",
       " 'each ',\n",
       " 'other ',\n",
       " 'than',\n",
       " '\\n',\n",
       " '    ',\n",
       " 'given ',\n",
       " 'threshol',\n",
       " 'd.',\n",
       " '\\n',\n",
       " '    >>> ',\n",
       " 'has_',\n",
       " 'close_',\n",
       " 'element',\n",
       " 's([',\n",
       " '1.0, ',\n",
       " '2.0, ',\n",
       " '3.',\n",
       " '0], ',\n",
       " '0.5)',\n",
       " '\\n',\n",
       " '    ',\n",
       " 'False',\n",
       " '\\n',\n",
       " '    >>> ',\n",
       " 'has_',\n",
       " 'close_',\n",
       " 'element',\n",
       " 's([',\n",
       " '1.0, ',\n",
       " '2.',\n",
       " '8, ',\n",
       " '3.0, ',\n",
       " '4.',\n",
       " '0, ',\n",
       " '5.0, ',\n",
       " '2.',\n",
       " '0]',\n",
       " ', 0.',\n",
       " '3)',\n",
       " '\\n',\n",
       " '    True',\n",
       " '\\n',\n",
       " '    \"\"\"',\n",
       " '\\n',\n",
       " '    for ',\n",
       " 'idx, ',\n",
       " 'ele',\n",
       " 'm in ',\n",
       " 'enumerate(',\n",
       " 'number',\n",
       " 's):',\n",
       " '\\n',\n",
       " '        for ',\n",
       " 'idx',\n",
       " '2, ',\n",
       " 'ele',\n",
       " 'm2',\n",
       " ' in enumerate(',\n",
       " 'number',\n",
       " 's):',\n",
       " '\\n',\n",
       " '            if ',\n",
       " 'idx ',\n",
       " '!= ',\n",
       " 'idx',\n",
       " '2:',\n",
       " '\\n',\n",
       " '<sentinel:0>',\n",
       " '                if ',\n",
       " 'distance ',\n",
       " '< ',\n",
       " 'threshold',\n",
       " ':',\n",
       " '\\n',\n",
       " '                    return ',\n",
       " 'True',\n",
       " '\\n\\n',\n",
       " '    return False',\n",
       " '<sentinel:1>',\n",
       " '<sentinel:0>',\n",
       " '                ',\n",
       " 'distance = ',\n",
       " 'abs(',\n",
       " 'elem ',\n",
       " '- ',\n",
       " 'elem',\n",
       " '2)',\n",
       " '\\n',\n",
       " '<eoss>']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[model._decode([x]) for x in response['choices'][0]['ids']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "23e0db32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n    for idx, elem in enumerate(numbers):\\n        for idx2, elem2 in enumerate(numbers):\\n            if idx != idx2:\\n',\n",
       " '                distance = abs(elem - elem2)\\n',\n",
       " '                if distance < threshold:\\n                    return True\\n\\n    return False']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['choices'][0]['complete']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bd8ad029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n    for idx, elem in enumerate(numbers):\\n        for idx2, elem2 in enumerate(numbers):\\n            if idx != idx2:\\n',\n",
       " '                distance = ',\n",
       " '                if distance < threshold:\\n                    return True\\n\\n    return False']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_stop['choices'][0]['complete']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9424b5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b76c570d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from infill_evaluation import eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c55f2580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 164/164 [19:22<00:00,  7.09s/it, pass=1, exact=1]\n"
     ]
    }
   ],
   "source": [
    "# sanity check that we get 100% pass when feeding the original problem\n",
    "\n",
    "# truncation_heuristics = [\"num_lines\", \"suffix\"]\n",
    "truncation_heuristics = []\n",
    "functional_results = []\n",
    "infill_results = []\n",
    "pbar = tqdm.tqdm(infill_problems)\n",
    "for task_id, task_id_problems in pbar:\n",
    "    if functional_results:\n",
    "        avg_pass = np.mean([x[\"passed\"] for x in functional_results])\n",
    "        avg_exact = np.mean([x[\"exact_match\"] for x in functional_results])\n",
    "        pbar.set_postfix({'pass': avg_pass, 'exact': avg_exact})\n",
    "    humaneval_problem = humaneval_problems[task_id]\n",
    "    for infilling_problem in task_id_problems:\n",
    "        prefix, suffix = infilling_problem[\"prompt_parts\"]\n",
    "        missing_lines = infilling_problem[\"missing_lines\"]\n",
    "        infill_result = infilling_problem.copy()\n",
    "        infill_result[\"text\"] = missing_lines\n",
    "        infill_result[\"text_untruncated\"] = missing_lines\n",
    "        complete = \"\\n\".join([prefix, missing_lines, suffix])\n",
    "        infill_result[\"complete\"] = complete\n",
    "        infill_results.append(infill_result)\n",
    "        functional_results.append(eval_result(\n",
    "            task_id, humaneval_problem, truncation_heuristics, infill_result\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec5440be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import TruncationParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "52d28185",
   "metadata": {},
   "outputs": [],
   "source": [
    "truncation_parameters = [TruncationParameters.from_heuristics(infill_args.truncation_heuristics, problem[\"missing_lines\"], suffix)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ec4044be",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = dict(\n",
    "    verbose=False, n=infill_args.num_candidates,\n",
    "    bidirectional_generation=infill_args.bidirectional_generation,\n",
    "    bidirectional_scoring=infill_args.bidirectional_scoring,\n",
    "    truncation_parameters=truncation_parameters,\n",
    "    scoring=infill_args.candidate_scoring,\n",
    ")\n",
    "# if args.temperature == 0.0:\n",
    "#     # kwargs.update(sampling=False)\n",
    "# else:\n",
    "kwargs.update(sampling=True, top_p=infill_args.top_p, temperature=infill_args.temperature)\n",
    "# kwargs.update(sampling=True, top_p=infill_args.top_p, temperature=0.8)\n",
    "# kwargs.update(max_tokens=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0df6fa07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': False,\n",
       " 'n': 1,\n",
       " 'bidirectional_generation': True,\n",
       " 'bidirectional_scoring': False,\n",
       " 'truncation_parameters': [TruncationParameters(max_num_lines=1, suffix='        for idx2, elem2 in enumerate(numbers):\\n            if idx != idx2:\\n                distance = abs(elem - elem2)\\n                if distance < threshold:\\n                    return True\\n\\n    return False')],\n",
       " 'scoring': 'random',\n",
       " 'sampling': True,\n",
       " 'top_p': 0.95,\n",
       " 'temperature': 0.2}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d363a795",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "87d6b88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: <eoss> not found\n"
     ]
    }
   ],
   "source": [
    "sorted_choices, response = model.rank_infills(prompt_parts, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ad65ffd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt_parts': ['from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n',\n",
       "  '        for idx2, elem2 in enumerate(numbers):\\n            if idx != idx2:\\n                distance = abs(elem - elem2)\\n                if distance < threshold:\\n                    return True\\n\\n    return False'],\n",
       " 'choices': [{'complete': ['from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n',\n",
       "    '    numbers = sorted(numbers)\\n    for idx, elem in enumerate(numbers):\\n        if idx != 0:\\n            distance = abs(elem - numbers[idx - 1])\\n            if distance < threshold:\\n                return True\\n\\n    return False\\n\\n\\ndef has_close_elements_list(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements_list([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements_list([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n    numbers = sorted(numbers)\\n    for idx, elem in enumerate(numbers):\\n        if idx != 0:',\n",
       "    '        for idx2, elem2 in enumerate(numbers):\\n            if idx != idx2:\\n                distance = abs(elem - elem2)\\n                if distance < threshold:\\n                    return True\\n\\n    return False'],\n",
       "   'infills_untruncated': ['    numbers = sorted(numbers)\\n    for idx, elem in enumerate(numbers):\\n        if idx != 0:\\n            distance = abs(elem - numbers[idx - 1])\\n            if distance < threshold:\\n                return True\\n\\n    return False\\n\\n\\ndef has_close_elements_list(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements_list([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements_list([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n    numbers = sorted(numbers)\\n    for idx, elem in enumerate(numbers):\\n        if idx != 0:'],\n",
       "   'ids': [48158,\n",
       "    536,\n",
       "    380,\n",
       "    4732,\n",
       "    14180,\n",
       "    1375,\n",
       "    484,\n",
       "    1726,\n",
       "    14641,\n",
       "    37417,\n",
       "    6342,\n",
       "    8660,\n",
       "    18567,\n",
       "    205,\n",
       "    7749,\n",
       "    13161,\n",
       "    366,\n",
       "    2649,\n",
       "    2433,\n",
       "    1726,\n",
       "    463,\n",
       "    937,\n",
       "    2193,\n",
       "    3510,\n",
       "    34254,\n",
       "    1304,\n",
       "    374,\n",
       "    1222,\n",
       "    2065,\n",
       "    2370,\n",
       "    20711,\n",
       "    205,\n",
       "    264,\n",
       "    2649,\n",
       "    13349,\n",
       "    696,\n",
       "    205,\n",
       "    2296,\n",
       "    4732,\n",
       "    14180,\n",
       "    1375,\n",
       "    8877,\n",
       "    6280,\n",
       "    22672,\n",
       "    1201,\n",
       "    13102,\n",
       "    12444,\n",
       "    205,\n",
       "    264,\n",
       "    690,\n",
       "    205,\n",
       "    2296,\n",
       "    4732,\n",
       "    14180,\n",
       "    1375,\n",
       "    8877,\n",
       "    6280,\n",
       "    845,\n",
       "    3554,\n",
       "    41762,\n",
       "    2409,\n",
       "    546,\n",
       "    41091,\n",
       "    845,\n",
       "    589,\n",
       "    3024,\n",
       "    2644,\n",
       "    205,\n",
       "    28660,\n",
       "    205,\n",
       "    768,\n",
       "    205,\n",
       "    50261,\n",
       "    1185,\n",
       "    2386,\n",
       "    867,\n",
       "    1702,\n",
       "    4445,\n",
       "    10200,\n",
       "    1726,\n",
       "    1138,\n",
       "    205,\n",
       "    952,\n",
       "    14602,\n",
       "    1371,\n",
       "    2386,\n",
       "    3105,\n",
       "    205,\n",
       "    288,\n",
       "    46087,\n",
       "    4933,\n",
       "    28334,\n",
       "    542,\n",
       "    9241,\n",
       "    1484,\n",
       "    205,\n",
       "    1667,\n",
       "    9130,\n",
       "    993,\n",
       "    6342,\n",
       "    32,\n",
       "    205,\n",
       "    6459,\n",
       "    617,\n",
       "    284,\n",
       "    31874,\n",
       "    50261,\n",
       "    264,\n",
       "    1726,\n",
       "    26366,\n",
       "    1726,\n",
       "    588,\n",
       "    205,\n",
       "    1553,\n",
       "    9314,\n",
       "    1702,\n",
       "    9292,\n",
       "    4338,\n",
       "    1726,\n",
       "    1138,\n",
       "    205,\n",
       "    563,\n",
       "    14602,\n",
       "    17351,\n",
       "    205,\n",
       "    292,\n",
       "    46087,\n",
       "    4933,\n",
       "    28334,\n",
       "    542,\n",
       "    1726,\n",
       "    24197,\n",
       "    9215,\n",
       "    9362,\n",
       "    205,\n",
       "    952,\n",
       "    9130,\n",
       "    993,\n",
       "    6342,\n",
       "    32,\n",
       "    205,\n",
       "    25564,\n",
       "    284,\n",
       "    31874,\n",
       "    536,\n",
       "    380,\n",
       "    4732,\n",
       "    14180,\n",
       "    1375,\n",
       "    386,\n",
       "    2484,\n",
       "    1726,\n",
       "    14641,\n",
       "    37417,\n",
       "    6342,\n",
       "    8660,\n",
       "    18567,\n",
       "    205,\n",
       "    7749,\n",
       "    13161,\n",
       "    366,\n",
       "    2649,\n",
       "    2433,\n",
       "    1726,\n",
       "    463,\n",
       "    937,\n",
       "    2193,\n",
       "    3510,\n",
       "    34254,\n",
       "    1304,\n",
       "    374,\n",
       "    1222,\n",
       "    2065,\n",
       "    2370,\n",
       "    20711,\n",
       "    205,\n",
       "    264,\n",
       "    2649,\n",
       "    13349,\n",
       "    696,\n",
       "    205,\n",
       "    2296,\n",
       "    4732,\n",
       "    14180,\n",
       "    1375,\n",
       "    5569,\n",
       "    1117,\n",
       "    6280,\n",
       "    22672,\n",
       "    1201,\n",
       "    13102,\n",
       "    12444,\n",
       "    205,\n",
       "    264,\n",
       "    690,\n",
       "    205,\n",
       "    2296,\n",
       "    4732,\n",
       "    14180,\n",
       "    1375,\n",
       "    5569,\n",
       "    1117,\n",
       "    6280,\n",
       "    845,\n",
       "    3554,\n",
       "    41762,\n",
       "    2409,\n",
       "    546,\n",
       "    41091,\n",
       "    845,\n",
       "    589,\n",
       "    3024,\n",
       "    2644,\n",
       "    205,\n",
       "    28660,\n",
       "    205,\n",
       "    768,\n",
       "    205,\n",
       "    264,\n",
       "    1726,\n",
       "    26366,\n",
       "    1726,\n",
       "    588,\n",
       "    205,\n",
       "    1553,\n",
       "    9314,\n",
       "    1702,\n",
       "    9292,\n",
       "    4338,\n",
       "    1726,\n",
       "    1138,\n",
       "    205,\n",
       "    563,\n",
       "    14602,\n",
       "    17351,\n",
       "    50517],\n",
       "   'logprobs': {'token_logprobs': [tensor([-2.2618e+00, -3.0078e-01, -1.1395e-01,  0.0000e+00,  0.0000e+00,\n",
       "             -4.8828e-04, -4.0039e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00, -6.1035e-05,  0.0000e+00, -4.2871e-01,\n",
       "             -2.8076e-03, -1.2626e+00,  0.0000e+00, -6.1035e-05,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "             -2.1973e-03,  0.0000e+00,  0.0000e+00, -6.1035e-05, -6.1035e-05,\n",
       "              0.0000e+00, -6.1035e-05,  0.0000e+00, -3.5962e-01, -8.5449e-04,\n",
       "             -6.1035e-05, -4.7406e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00,  0.0000e+00, -8.6060e-03,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "              0.0000e+00, -2.9785e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00,  0.0000e+00, -6.1035e-05,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00,  0.0000e+00], device='cuda:0')],\n",
       "    'tokens': None}}]}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "becd1228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['complete', 'infills', 'infills_untruncated', 'logprobs'])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_choices[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bf52ca73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'complete': 'from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n    numbers = sorted(numbers)\\n        for idx2, elem2 in enumerate(numbers):\\n            if idx != idx2:\\n                distance = abs(elem - elem2)\\n                if distance < threshold:\\n                    return True\\n\\n    return False',\n",
       " 'infills': ['    numbers = sorted(numbers)'],\n",
       " 'infills_untruncated': ['    numbers = sorted(numbers)\\n    for idx, elem in enumerate(numbers):\\n        if idx != 0:\\n            distance = abs(elem - numbers[idx - 1])\\n            if distance < threshold:\\n                return True\\n\\n    return False\\n\\n\\ndef has_close_elements_list(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements_list([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements_list([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n    numbers = sorted(numbers)\\n    for idx, elem in enumerate(numbers):\\n        if idx != 0:'],\n",
       " 'logprobs': {'token_logprobs': None, 'tokens': None}}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_choices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dbfe6c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_overlap(infill, suffix, minimum_num_characters=None, minimum_num_suffix_lines=1):\n",
    "    if minimum_num_characters is None:\n",
    "        non_empty_suffix_lines = [l.strip() for l in suffix.strip(\"\\n\") if l.strip()]\n",
    "        minimum_num_characters = sum(len(l) for l in non_empty_suffix_lines[:minimum_num_suffix_lines])\n",
    "    for i in range(len(infill), minimum_num_characters, -1):\n",
    "        if infill[-i:] == suffix[:i]:\n",
    "            return infill[:-i]\n",
    "    return infill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "07337107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "pdb on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cf893414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-174.8389892578125]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score_text([sorted_choices[6]['complete']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "801c0a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.5474575757980347,\n",
       " -1.5674219131469727,\n",
       " -1.5674219131469727,\n",
       " -1.5474575757980347,\n",
       " -1.5474575757980347,\n",
       " -1.5564860105514526,\n",
       " -1.5474575757980347,\n",
       " -1.5564860105514526,\n",
       " -1.5671440362930298,\n",
       " -1.5671440362930298]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score_text([choice['complete'] for choice in sorted_choices], 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8b80e5ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n    numbers.sort()\\n        for idx2, elem2 in enumerate(numbers):\\n            if idx != idx2:\\n                distance = abs(elem - elem2)\\n                if distance < threshold:\\n                    return True\\n\\n    return False'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choice['complete']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f8c60354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['                if distance < threshold:'],\n",
       " ['                if distance > threshold:'],\n",
       " ['                if distance > threshold:'],\n",
       " ['                if distance < threshold:'],\n",
       " ['                if distance < threshold:'],\n",
       " ['                if distance <= threshold:'],\n",
       " ['                if distance < threshold:'],\n",
       " ['                if distance <= threshold:'],\n",
       " ['                if distance > threshold:'],\n",
       " ['                if distance > threshold:']]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[choice['infills'] for choice in sorted_choices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83bb92c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import OpenAIModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8ffd6c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of models failed: Traceback (most recent call last):\n",
      "  File \"/private/home/dpf/.conda/envs/fairseq-20210318-htlm_2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/private/home/dpf/.conda/envs/fairseq-20210318-htlm_2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 410, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/private/home/dpf/.conda/envs/fairseq-20210318-htlm_2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/private/home/dpf/.conda/envs/fairseq-20210318-htlm_2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 317, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"/private/home/dpf/.conda/envs/fairseq-20210318-htlm_2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 280, in update_instances\n",
      "    ref.__class__ = new\n",
      "TypeError: __class__ assignment: 'TruncationParameters' object layout differs from 'TruncationParameters'\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "codex = OpenAIModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8768eb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from secret import API_KEY\n",
    "openai.api_key = API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb60382a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from infill_evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3da929b",
   "metadata": {},
   "outputs": [],
   "source": [
    "infill_problems = list(generate_he_infill_problems(args, \"one_line\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bd96a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix, suffix = infill_problems[0][1][0]['prompt_parts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8560786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from typing import List\n",
      "\n",
      "\n",
      "def has_close_elements(numbers: List[float], threshold: float) -> bool:\n",
      "    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\n",
      "    given threshold.\n",
      "    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\n",
      "    False\n",
      "    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n",
      "    True\n",
      "    \"\"\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "989bf3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        for idx2, elem2 in enumerate(numbers):\n",
      "            if idx != idx2:\n",
      "                distance = abs(elem - elem2)\n",
      "                if distance < threshold:\n",
      "                    return True\n",
      "\n",
      "    return False\n"
     ]
    }
   ],
   "source": [
    "print(suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b00cdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "    engine=\"code-davinci-002\",\n",
    "    prompt=prefix,\n",
    "    suffix=suffix,\n",
    "    logprobs=1,\n",
    "    max_tokens=128,\n",
    "    temperature=0.2,\n",
    "    echo=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4ab4628",
   "metadata": {},
   "outputs": [],
   "source": [
    "choice = response['choices'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2dd1eafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    for idx, elem in enumerate(numbers):\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choice['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e5be876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import make_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9ed678df",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_model_name = '/checkpoint/dpf/models/cm-6B-armen/checkpoint_last_consolidated.pt'\n",
    "infill_args.model_name = 'code-davinci-002'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0a4dd759",
   "metadata": {},
   "outputs": [],
   "source": [
    "infill_args.prompt_prefix = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82925890",
   "metadata": {},
   "outputs": [],
   "source": [
    "infill_args.engine='code_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "99c5ec6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(batch_size=10, beam=1, bidirectional_generation=True, bidirectional_scoring=False, candidate_scoring='random', eval_type='one_line', evaluate_only=False, git_status=False, max_infill_attempts=1, max_tokens=450, model_name='code-davinci-002', num_candidates=1, prompt_prefix=None, result_base_path=None, temperature=0.2, tokenizer_name='gpt2_pretokenization_newlines_only', top_p=0.95, truncation_heuristics=['num_lines', 'suffix'])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infill_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b4885c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3741bf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of models failed: Traceback (most recent call last):\n",
      "  File \"/private/home/dpf/.conda/envs/fairseq-20210318-htlm_2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/private/home/dpf/.conda/envs/fairseq-20210318-htlm_2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 410, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/private/home/dpf/.conda/envs/fairseq-20210318-htlm_2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/private/home/dpf/.conda/envs/fairseq-20210318-htlm_2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 317, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"/private/home/dpf/.conda/envs/fairseq-20210318-htlm_2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 280, in update_instances\n",
      "    ref.__class__ = new\n",
      "TypeError: __class__ assignment: 'TruncationParameters' object layout differs from 'TruncationParameters'\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "codex_model = make_model(infill_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b5d3082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = codex_model.infill([prefix, suffix], temperature=1.0, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4b95961c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    for idx, elem in enumerate(numbers):\n",
      "\n",
      "    for idx, elem in enumerate(numbers):\n",
      "\n",
      "    for idx, elem in enumerate(numbers):\n",
      "\n",
      "    for idx, elem in enumerate(numbers):\n",
      "\n",
      "    for idx, elem in enumerate(numbers):\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for choice in response['choices']:\n",
    "    print(choice['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "99b36353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    for idx, elem in enumerate(numbers):\\n'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7800076b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stop'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['choices'][0]['finish_reason']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
