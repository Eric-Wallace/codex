{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa443763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/private/home/dpf/projects/codex/notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d1543aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/private/home/dpf/projects/codex\n"
     ]
    }
   ],
   "source": [
    "cd /private/home/dpf/projects/codex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79fe7dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typewriter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab4f3dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99a9f904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "pdb on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d479f1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import astunparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd1d8fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from type_hints import normalize_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5279594a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "typewriter_dir = \"/private/home/dpf/data/TypeWriter_dataset\"\n",
    "crawl_root = \"/checkpoint/dpf/data/typewriter/crawl/data\"\n",
    "split = 'validation'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e93699f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before removing crawled repos: 272\n",
      "after removing crawled repos: 272\n",
      "archive /checkpoint/dpf/data/typewriter/crawl/data/productml/blurr.json.zstd not found; removing from repos\n",
      "archive /checkpoint/dpf/data/typewriter/crawl/data/b2wdigital/aiologger.json.zstd not found; removing from repos\n",
      "archive /checkpoint/dpf/data/typewriter/crawl/data/CasperLabs/CasperLabs.json.zstd not found; removing from repos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 16492/16492 [01:50<00:00, 149.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'no repo': 11034, 'no ast match': 547, 'file mismatch 0': 69})\n",
      "return: skipped 11650 / 16492 examples (4842 remaining)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "decontaminate = True\n",
    "imports_and_function_only = True\n",
    "\n",
    "examples = build_examples(typewriter_dir, crawl_root, imports_and_function_only, split=split, show_tqdm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "81d02bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14591"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(80341 - 7383) // 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e9029d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.744053851907255,\n",
       " 'recall': 0.6032015522677662,\n",
       " 'f1': 0.6662648181635523,\n",
       " 'n_correct': 9948,\n",
       " 'n_predictions': 13370,\n",
       " 'n_types': 16492}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typewriter_predictions = get_typewriter_predictions(read_prediction_file(typewriter_dir, argument=False))\n",
    "evaluate(typewriter_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "87e971af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.7539279671259367,\n",
       " 'recall': 0.6441553077240809,\n",
       " 'f1': 0.69473215280098,\n",
       " 'n_correct': 3119,\n",
       " 'n_predictions': 4137,\n",
       " 'n_types': 4842}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typewriter_predictions_filtered = get_typewriter_predictions(examples)\n",
    "evaluate(typewriter_predictions_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "98b82672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.5952380952380952,\n",
       " 'recall': 0.5,\n",
       " 'f1': 0.5434782608695652,\n",
       " 'n_correct': 50,\n",
       " 'n_predictions': 84,\n",
       " 'n_types': 100}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typewriter_predictions_filtered = get_typewriter_predictions(examples)\n",
    "evaluate(typewriter_predictions_filtered[:100], type_from_source=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b726bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36cfdfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import os\n",
    "\n",
    "line_url_re = re.compile(r'https://github.com/(.*)/(.*)\\.git::(.*)')\n",
    "arg_re = re.compile(r'(\\d+)->\\[(.*)\\]')\n",
    "\n",
    "def read_github_url_file(path):\n",
    "    repo_to_commit = {}\n",
    "    repo_to_name = {}\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            match = line_url_re.match(line.strip())\n",
    "            user, repo, commit = match.groups()\n",
    "            assert repo not in repo_to_commit\n",
    "            repo_to_commit[repo] = commit\n",
    "            repo_to_name[repo] = f'{user}/{repo}'\n",
    "    return repo_to_commit, repo_to_name\n",
    "\n",
    "def read_filename_file(path):\n",
    "    names_to_paths = {}\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            split = line.split('/')\n",
    "            repo, *rest = split\n",
    "            name = repo\n",
    "            if name not in names_to_paths:\n",
    "                names_to_paths[name] = []\n",
    "            names_to_paths[name].append('/'.join(rest))\n",
    "    return names_to_paths\n",
    "\n",
    "def read_prediction_file(path, argument=False):\n",
    "    prefix = \"/home/anon/local/github-repos/\"\n",
    "    with open(path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    records = []\n",
    "    for key, answers in data.items():\n",
    "        key = key.strip()\n",
    "        file, location = key.split(' : ')\n",
    "        if argument:\n",
    "            line_num, var = arg_re.match(location).groups()\n",
    "            line_num = int(line_num)\n",
    "        else:\n",
    "            line_num = int(location)\n",
    "        assert file.startswith(prefix)\n",
    "        repo, *rest = file.lstrip(prefix).split('/')\n",
    "        path = '/'.join(rest)\n",
    "        gold = answers[0]\n",
    "        predicted = answers[1]\n",
    "        record = {\n",
    "            'repo': repo,\n",
    "            'path': path,\n",
    "            'line_number': line_num,\n",
    "            'true_type': gold,\n",
    "            'predicted_types': predicted\n",
    "        }\n",
    "        if argument:\n",
    "            record['variable'] = var\n",
    "        records.append(record)\n",
    "    return records\n",
    "\n",
    "def read_typewriter_validation(typewriter_dir):\n",
    "    repo_to_commit, repo_to_name = read_github_url_file(os.path.join(typewriter_dir, 'github_urls.txt'))\n",
    "    # Dict[str, List[str]]: name -> paths\n",
    "    repo_to_paths = read_filename_file(os.path.join(typewriter_dir, 'open_source_validation_files.txt'))\n",
    "    return repo_to_commit, repo_to_name, repo_to_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebb1c4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_to_commit, repo_to_name, repo_to_path = read_typewriter_validation('/private/home/dpf/data/TypeWriter_dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab5b3874",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = read_prediction_file('/private/home/dpf/data/TypeWriter_dataset/open_source_results_return.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b21e7b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_predictions = read_prediction_file('/private/home/dpf/data/TypeWriter_dataset/open_source_results_argument.json', argument=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce8bbd3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21215"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arg_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffde8119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'repo': 'ycharm-course',\n",
       " 'path': 'extra_samples/parsing/numparser.py',\n",
       " 'line_number': 4,\n",
       " 'true_type': 'str',\n",
       " 'predicted_types': ['str', 'bytes', 'Text', 'Optional[str]', 'LongTensor'],\n",
       " 'variable': 'text'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arg_predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6daa1fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_names = set(\n",
    "    repo_to_name[repo] for repo in repo_to_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be9f80e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98b65df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5a53719",
   "metadata": {},
   "outputs": [],
   "source": [
    "crawled_repos = set()\n",
    "for fname in glob.glob('/checkpoint/dpf/data/github/*.csv'):\n",
    "    with open(fname, 'r') as f:\n",
    "        for record in csv.DictReader(f):\n",
    "            if 'name' in record:\n",
    "                key = 'name'\n",
    "            else:\n",
    "                key = 'repo_name'\n",
    "                assert key in record\n",
    "            crawled_repos.add(record[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41d4be58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "681590"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(crawled_repos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00e526e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_to_path_decon = {\n",
    "    repo: paths for repo, paths in repo_to_path.items()\n",
    "    if repo_to_name[repo] not in crawled_repos\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f91da5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1936"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(len(paths) for repo, paths in repo_to_path.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a1e19ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1229"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(len(paths) for repo, paths in repo_to_path_decon.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86e97ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6348140495867769"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1229 / 1936"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa4a8293",
   "metadata": {},
   "outputs": [],
   "source": [
    "crawl_root = '/checkpoint/dpf/data/typewriter/crawl/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ef2cedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zstandard as zstd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7274cf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressor = zstd.ZstdDecompressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a28a662c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "archive /checkpoint/dpf/data/typewriter/crawl/data/productml/blurr.json.zstd not found\n",
      "archive /checkpoint/dpf/data/typewriter/crawl/data/CasperLabs/CasperLabs.json.zstd not found\n"
     ]
    }
   ],
   "source": [
    "repo_to_archive_decon = {}\n",
    "for repo, paths in repo_to_path_decon.items():\n",
    "    name = repo_to_name[repo]\n",
    "    archive_fname = os.path.join(crawl_root, f\"{name}.json.zstd\")\n",
    "    if not os.path.exists(archive_fname):\n",
    "        print(f\"archive {archive_fname} not found\")\n",
    "        continue\n",
    "    with open(archive_fname, 'rb') as f:\n",
    "        reader = compressor.stream_reader(f)\n",
    "        archive = json.load(reader)\n",
    "        repo_to_archive_decon[repo] = archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c488142",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install astunparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4503d505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'repo': 'ycharm-course',\n",
       " 'path': 'extra_samples/parsing/numparser.py',\n",
       " 'line_number': 4,\n",
       " 'true_type': 'List[int]',\n",
       " 'predicted_types': ['JavaObject', 'SpanContext', 'ndarray', 'dtype', 'Model']}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "762c1de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_decon = [pred for pred in predictions if pred['repo'] in repo_to_archive_decon]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11de060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_predictions_decon = [pred for pred in arg_predictions if pred['repo'] in repo_to_archive_decon]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1cb491ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16492"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "717196b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4680"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions_decon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2120f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5121"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arg_predictions_decon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1478fd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21215"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arg_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "926a6c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24138581192552439"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arg_predictions_decon) / len(arg_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "70b9fd07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'repo': 'dbt',\n",
       " 'path': 'core/dbt/node_runners.py',\n",
       " 'line_number': 74,\n",
       " 'true_type': 'Any',\n",
       " 'predicted_types': ['None', 'Dict[str, Any]', 'str', '@@UNK@@', 'List[str]']}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_decon[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9836f79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_data = repo_to_archive_decon[predictions_decon[0]['repo']]['file_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe2e2378",
   "metadata": {},
   "outputs": [],
   "source": [
    "datum = next(datum for datum in file_data if datum['path'] == predictions_decon[0]['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f121b61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "efe4929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = datum['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a9e40142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import type_hints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0415c030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast, astunparse\n",
    "from type_hints import TypeHintRemover, derive_prefix_suffix, TypeHintKeepOnlyTargeted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fbbb9f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'node': <_ast.FunctionDef at 0x7f9c56560990>,\n",
       "  'returns': <_ast.Name at 0x7f9c56560b90>}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "453f804a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'commit_info': [{'authored_date': 1582613019,\n",
       "   'commit_id': 'a5c83dad8382a1f407a0158ff14514f9369b265e',\n",
       "   'committed_date': 1582613019,\n",
       "   'diffs': [{'diff': '', 'path': 'todo/views/import_csv.py'}]}],\n",
       " 'commits_and_paths': [{'commit_id': 'a5c83dad8382a1f407a0158ff14514f9369b265e',\n",
       "   'paths': ['todo/views/import_csv.py']}],\n",
       " 'file_data': [{'commit_id': 'a5c83dad8382a1f407a0158ff14514f9369b265e',\n",
       "   'content': 'from django.contrib import messages\\nfrom django.contrib.auth.decorators import login_required, user_passes_test\\nfrom django.http import HttpResponse\\nfrom django.shortcuts import redirect, render, reverse\\n\\nfrom todo.operations.csv_importer import CSVImporter\\nfrom todo.utils import staff_check\\n\\n\\n@login_required\\n@user_passes_test(staff_check)\\ndef import_csv(request) -> HttpResponse:\\n    \"\"\"Import a specifically formatted CSV into stored tasks.\\n    \"\"\"\\n\\n    ctx = {\"results\": None}\\n\\n    if request.method == \"POST\":\\n        filepath = request.FILES.get(\"csvfile\")\\n\\n        if not filepath:\\n            messages.error(request, \"You must supply a CSV file to import.\")\\n            return redirect(reverse(\"todo:import_csv\"))\\n\\n        importer = CSVImporter()\\n        results = importer.upsert(filepath)\\n\\n        if results:\\n            ctx[\"results\"] = results\\n        else:\\n            messages.error(request, \"Could not parse provided CSV file.\")\\n            return redirect(reverse(\"todo:import_csv\"))\\n\\n    return render(request, \"todo/import_csv.html\", context=ctx)\\n',\n",
       "   'path': 'todo/views/import_csv.py'}],\n",
       " 'missing_commits': [],\n",
       " 'name': 'shacker/django-todo'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8ebc5c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_return_example(source: str, lineno: int, return_type: str, imports_and_function=True):\n",
    "    def match_with_type(function, returns):\n",
    "        return astunparse.unparse(returns).strip() == return_type\n",
    "    def match_with_line_and_type(function, returns):\n",
    "        return match_with_type(function, returns) and lineno == function.lineno\n",
    "    processor = TypeHintKeepOnlyTargeted(['return'], match_with_line_and_type)\n",
    "    parsed_source = ast.parse(content)\n",
    "    # remove the type annotations, except for the target\n",
    "    processor.visit(parsed_source)\n",
    "    assert len(processor.matches) == 1\n",
    "    # now reparse, but only needing to keep the type\n",
    "#     processor = TypeHintKeepOnlyTargeted(['return'], match_with_type, remove_type_imports=False)\n",
    "#     processor.visit(ast.parse(clean_source))\n",
    "#     assert len(procsssor.matches) == 1\n",
    "#     clean_lines = clean_source.splitlines()\n",
    "    \n",
    "    if imports_and_function:\n",
    "        extra_left = [astunparse.unparse(node).strip() for node in processor.imports]\n",
    "        to_split = astunparse.unparse(processor.matches[0]['node'])\n",
    "    else:\n",
    "        extra_left = []\n",
    "        to_split = astunparse.unparse(parsed_source)\n",
    "    pairs = list(derive_prefix_suffix(to_split, f\" -> {return_type}\"))\n",
    "    assert len(pairs) == 1\n",
    "    left, right = pairs[0]\n",
    "    return {\n",
    "        'extra_left': extra_left,\n",
    "        'left': left + ' -> ',\n",
    "        'right': right,\n",
    "        'return_type': return_type,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dc3e05b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'extra_left': ['import abc',\n",
       "  'import threading',\n",
       "  'import time',\n",
       "  'import traceback',\n",
       "  'from typing import List, Dict, Any, Optional',\n",
       "  'from dbt import deprecations',\n",
       "  'from dbt.adapters.base import BaseRelation',\n",
       "  'from dbt.clients.jinja import MacroGenerator',\n",
       "  'from dbt.compilation import compile_node',\n",
       "  'from dbt.context.providers import generate_runtime_model',\n",
       "  'from dbt.contracts.graph.manifest import Manifest',\n",
       "  'from dbt.contracts.results import RunModelResult, collect_timing_info, SourceFreshnessResult, PartialResult',\n",
       "  'from dbt.exceptions import NotImplementedException, CompilationException, RuntimeException, InternalException, missing_materialization',\n",
       "  'from dbt.logger import GLOBAL_LOGGER as logger',\n",
       "  'from dbt.node_types import NodeType',\n",
       "  'import dbt.exceptions',\n",
       "  'import dbt.tracking',\n",
       "  'import dbt.ui.printer',\n",
       "  'import dbt.flags'],\n",
       " 'left': '\\n\\n@abc.abstractmethod\\ndef compile(self, manifest) -> ',\n",
       " 'right': ':\\n    pass\\n',\n",
       " 'return_type': 'Any'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_return_example(content, rpedi, 'Any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bb4e3cd4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import abc\n",
      "import threading\n",
      "import time\n",
      "import traceback\n",
      "from typing import List, Dict, Any, Optional\n",
      "from dbt import deprecations\n",
      "from dbt.adapters.base import BaseRelation\n",
      "from dbt.clients.jinja import MacroGenerator\n",
      "from dbt.compilation import compile_node\n",
      "from dbt.context.providers import generate_runtime_model\n",
      "from dbt.contracts.graph.manifest import Manifest\n",
      "from dbt.contracts.results import RunModelResult, collect_timing_info, SourceFreshnessResult, PartialResult\n",
      "from dbt.exceptions import NotImplementedException, CompilationException, RuntimeException, InternalException, missing_materialization\n",
      "from dbt.logger import GLOBAL_LOGGER as logger\n",
      "from dbt.node_types import NodeType\n",
      "import dbt.exceptions\n",
      "import dbt.tracking\n",
      "import dbt.ui.printer\n",
      "import dbt.flags\n",
      "INTERNAL_ERROR_STRING = 'This is an error in dbt. Please try again. If the error persists, open an issue at https://github.com/fishtown-analytics/dbt\\n'.strip()\n",
      "\n",
      "def track_model_run(index, num_nodes, run_model_result):\n",
      "    if (dbt.tracking.active_user is None):\n",
      "        raise InternalException('cannot track model run with no active user')\n",
      "    invocation_id = dbt.tracking.active_user.invocation_id\n",
      "    dbt.tracking.track_model_run({'invocation_id': invocation_id, 'index': index, 'total': num_nodes, 'execution_time': run_model_result.execution_time, 'run_status': run_model_result.status, 'run_skipped': run_model_result.skip, 'run_error': None, 'model_materialization': run_model_result.node.get_materialization(), 'model_id': dbt.utils.get_hash(run_model_result.node), 'hashed_contents': dbt.utils.get_hashed_contents(run_model_result.node), 'timing': [t.to_dict() for t in run_model_result.timing]})\n",
      "\n",
      "class ExecutionContext():\n",
      "    'During execution and error handling, dbt makes use of mutable state:\\n    timing information and the newest (compiled vs executed) form of the node.\\n    '\n",
      "\n",
      "    def __init__(self, node):\n",
      "        self.timing = []\n",
      "        self.node = node\n",
      "\n",
      "class BaseRunner(metaclass=abc.ABCMeta):\n",
      "\n",
      "    def __init__(self, config, adapter, node, node_index, num_nodes):\n",
      "        self.config = config\n",
      "        self.adapter = adapter\n",
      "        self.node = node\n",
      "        self.node_index = node_index\n",
      "        self.num_nodes = num_nodes\n",
      "        self.skip = False\n",
      "        self.skip_cause: Optional[RunModelResult] = None\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def compile(self, manifest) -> Any:\n",
      "        pass\n",
      "\n",
      "    def get_result_status(self, result):\n",
      "        if result.error:\n",
      "            return {'node_status': 'error', 'node_error': str(result.error)}\n",
      "        elif result.skip:\n",
      "            return {'node_status': 'skipped'}\n",
      "        elif result.fail:\n",
      "            return {'node_status': 'failed'}\n",
      "        elif result.warn:\n",
      "            return {'node_status': 'warn'}\n",
      "        else:\n",
      "            return {'node_status': 'passed'}\n",
      "\n",
      "    def run_with_hooks(self, manifest):\n",
      "        if self.skip:\n",
      "            return self.on_skip()\n",
      "        if (not self.node.is_ephemeral_model):\n",
      "            self.before_execute()\n",
      "        result = self.safe_run(manifest)\n",
      "        if (not self.node.is_ephemeral_model):\n",
      "            self.after_execute(result)\n",
      "        return result\n",
      "\n",
      "    def _build_run_result(self, node, start_time, error, status, timing_info, skip=False, fail=None, warn=None, agate_table=None):\n",
      "        execution_time = (time.time() - start_time)\n",
      "        thread_id = threading.current_thread().name\n",
      "        return RunModelResult(node=node, error=error, skip=skip, status=status, fail=fail, warn=warn, execution_time=execution_time, thread_id=thread_id, timing=timing_info, agate_table=agate_table)\n",
      "\n",
      "    def error_result(self, node, error, start_time, timing_info):\n",
      "        return self._build_run_result(node=node, start_time=start_time, error=error, status='ERROR', timing_info=timing_info)\n",
      "\n",
      "    def ephemeral_result(self, node, start_time, timing_info):\n",
      "        return self._build_run_result(node=node, start_time=start_time, error=None, status=None, timing_info=timing_info)\n",
      "\n",
      "    def from_run_result(self, result, start_time, timing_info):\n",
      "        return self._build_run_result(node=result.node, start_time=start_time, error=result.error, skip=result.skip, status=result.status, fail=result.fail, warn=result.warn, timing_info=timing_info, agate_table=result.agate_table)\n",
      "\n",
      "    def compile_and_execute(self, manifest, ctx):\n",
      "        result = None\n",
      "        with self.adapter.connection_for(self.node):\n",
      "            with collect_timing_info('compile') as timing_info:\n",
      "                ctx.node = self.compile(manifest)\n",
      "            ctx.timing.append(timing_info)\n",
      "            if (not ctx.node.is_ephemeral_model):\n",
      "                with collect_timing_info('execute') as timing_info:\n",
      "                    result = self.run(ctx.node, manifest)\n",
      "                    ctx.node = result.node\n",
      "                ctx.timing.append(timing_info)\n",
      "        return result\n",
      "\n",
      "    def _handle_catchable_exception(self, e, ctx):\n",
      "        if (e.node is None):\n",
      "            e.node = ctx.node\n",
      "        logger.debug(str(e), exc_info=True)\n",
      "        return str(e)\n",
      "\n",
      "    def _handle_internal_exception(self, e, ctx):\n",
      "        build_path = self.node.build_path\n",
      "        prefix = 'Internal error executing {}'.format(build_path)\n",
      "        error = '{prefix}\\n{error}\\n\\n{note}'.format(prefix=dbt.ui.printer.red(prefix), error=str(e).strip(), note=INTERNAL_ERROR_STRING)\n",
      "        logger.debug(error, exc_info=True)\n",
      "        return str(e)\n",
      "\n",
      "    def _handle_generic_exception(self, e, ctx):\n",
      "        node_description = self.node.build_path\n",
      "        if (node_description is None):\n",
      "            node_description = self.node.unique_id\n",
      "        prefix = 'Unhandled error while executing {}'.format(node_description)\n",
      "        error = '{prefix}\\n{error}'.format(prefix=dbt.ui.printer.red(prefix), error=str(e).strip())\n",
      "        logger.error(error)\n",
      "        logger.debug('', exc_info=True)\n",
      "        return str(e)\n",
      "\n",
      "    def handle_exception(self, e, ctx):\n",
      "        catchable_errors = (CompilationException, RuntimeException)\n",
      "        if isinstance(e, catchable_errors):\n",
      "            error = self._handle_catchable_exception(e, ctx)\n",
      "        elif isinstance(e, InternalException):\n",
      "            error = self._handle_internal_exception(e, ctx)\n",
      "        else:\n",
      "            error = self._handle_generic_exception(e, ctx)\n",
      "        return error\n",
      "\n",
      "    def safe_run(self, manifest):\n",
      "        started = time.time()\n",
      "        ctx = ExecutionContext(self.node)\n",
      "        error = None\n",
      "        result = None\n",
      "        try:\n",
      "            result = self.compile_and_execute(manifest, ctx)\n",
      "        except Exception as e:\n",
      "            error = self.handle_exception(e, ctx)\n",
      "        finally:\n",
      "            exc_str = self._safe_release_connection()\n",
      "            if ((exc_str is not None) and (result is not None) and (result.error is None) and (error is None)):\n",
      "                error = exc_str\n",
      "        if (error is not None):\n",
      "            result = self.error_result(ctx.node, error, started, [])\n",
      "        elif (result is not None):\n",
      "            result = self.from_run_result(result, started, ctx.timing)\n",
      "        else:\n",
      "            result = self.ephemeral_result(ctx.node, started, ctx.timing)\n",
      "        return result\n",
      "\n",
      "    def _safe_release_connection(self):\n",
      "        'Try to release a connection. If an exception is hit, log and return\\n        the error string.\\n        '\n",
      "        try:\n",
      "            self.adapter.release_connection()\n",
      "        except Exception as exc:\n",
      "            logger.debug('Error releasing connection for node {}: {!s}\\n{}'.format(self.node.name, exc, traceback.format_exc()))\n",
      "            return str(exc)\n",
      "        return None\n",
      "\n",
      "    def before_execute(self):\n",
      "        raise NotImplementedException()\n",
      "\n",
      "    def execute(self, compiled_node, manifest):\n",
      "        raise NotImplementedException()\n",
      "\n",
      "    def run(self, compiled_node, manifest):\n",
      "        return self.execute(compiled_node, manifest)\n",
      "\n",
      "    def after_execute(self, result):\n",
      "        raise NotImplementedException()\n",
      "\n",
      "    def _skip_caused_by_ephemeral_failure(self):\n",
      "        if ((self.skip_cause is None) or (self.skip_cause.node is None)):\n",
      "            return False\n",
      "        return self.skip_cause.node.is_ephemeral_model\n",
      "\n",
      "    def on_skip(self):\n",
      "        schema_name = self.node.schema\n",
      "        node_name = self.node.name\n",
      "        error = None\n",
      "        if (not self.node.is_ephemeral_model):\n",
      "            if self._skip_caused_by_ephemeral_failure():\n",
      "                dbt.ui.printer.print_skip_caused_by_error(self.node, schema_name, node_name, self.node_index, self.num_nodes, self.skip_cause)\n",
      "                if (self.skip_cause is None):\n",
      "                    raise InternalException('Skip cause not set but skip was somehow caused by an ephemeral failure')\n",
      "                error = 'Compilation Error in {}, caused by compilation error in referenced ephemeral model {}'.format(self.node.unique_id, self.skip_cause.node.unique_id)\n",
      "            else:\n",
      "                dbt.ui.printer.print_skip_line(self.node, schema_name, node_name, self.node_index, self.num_nodes)\n",
      "        node_result = RunModelResult(self.node, skip=True, error=error)\n",
      "        return node_result\n",
      "\n",
      "    def do_skip(self, cause=None):\n",
      "        self.skip = True\n",
      "        self.skip_cause = cause\n",
      "\n",
      "class CompileRunner(BaseRunner):\n",
      "\n",
      "    def before_execute(self):\n",
      "        pass\n",
      "\n",
      "    def after_execute(self, result):\n",
      "        pass\n",
      "\n",
      "    def execute(self, compiled_node, manifest):\n",
      "        return RunModelResult(compiled_node)\n",
      "\n",
      "    def compile(self, manifest):\n",
      "        return compile_node(self.adapter, self.config, self.node, manifest, {})\n",
      "\n",
      "def _validate_materialization_relations_dict(inp, model):\n",
      "    try:\n",
      "        relations_value = inp['relations']\n",
      "    except KeyError:\n",
      "        msg = 'Invalid return value from materialization, \"relations\" not found, got keys: {}'.format(list(inp))\n",
      "        raise CompilationException(msg, node=model) from None\n",
      "    if (not isinstance(relations_value, list)):\n",
      "        msg = 'Invalid return value from materialization, \"relations\" not a list, got: {}'.format(relations_value)\n",
      "        raise CompilationException(msg, node=model) from None\n",
      "    relations: List[BaseRelation] = []\n",
      "    for relation in relations_value:\n",
      "        if (not isinstance(relation, BaseRelation)):\n",
      "            msg = 'Invalid return value from materialization, \"relations\" contains non-Relation: {}'.format(relation)\n",
      "            raise CompilationException(msg, node=model)\n",
      "        assert isinstance(relation, BaseRelation)\n",
      "        relations.append(relation)\n",
      "    return relations\n",
      "\n",
      "class ModelRunner(CompileRunner):\n",
      "\n",
      "    def get_node_representation(self):\n",
      "        if (self.config.credentials.database == self.node.database):\n",
      "            template = '{0.schema}.{0.alias}'\n",
      "        else:\n",
      "            template = '{0.database}.{0.schema}.{0.alias}'\n",
      "        return template.format(self.node)\n",
      "\n",
      "    def describe_node(self):\n",
      "        return '{} model {}'.format(self.node.get_materialization(), self.get_node_representation())\n",
      "\n",
      "    def print_start_line(self):\n",
      "        description = self.describe_node()\n",
      "        dbt.ui.printer.print_start_line(description, self.node_index, self.num_nodes)\n",
      "\n",
      "    def print_result_line(self, result):\n",
      "        description = self.describe_node()\n",
      "        dbt.ui.printer.print_model_result_line(result, description, self.node_index, self.num_nodes)\n",
      "\n",
      "    def before_execute(self):\n",
      "        self.print_start_line()\n",
      "\n",
      "    def after_execute(self, result):\n",
      "        track_model_run(self.node_index, self.num_nodes, result)\n",
      "        self.print_result_line(result)\n",
      "\n",
      "    def _build_run_model_result(self, model, context):\n",
      "        result = context['load_result']('main')\n",
      "        return RunModelResult(model, status=result.status)\n",
      "\n",
      "    def _materialization_relations(self, result, model):\n",
      "        if isinstance(result, str):\n",
      "            deprecations.warn('materialization-return', materialization=model.get_materialization())\n",
      "            return [self.adapter.Relation.create_from(self.config, model)]\n",
      "        if isinstance(result, dict):\n",
      "            return _validate_materialization_relations_dict(result, model)\n",
      "        msg = 'Invalid return value from materialization, expected a dict with key \"relations\", got: {}'.format(str(result))\n",
      "        raise CompilationException(msg, node=model)\n",
      "\n",
      "    def execute(self, model, manifest):\n",
      "        context = generate_runtime_model(model, self.config, manifest)\n",
      "        materialization_macro = manifest.find_materialization_macro_by_name(self.config.project_name, model.get_materialization(), self.adapter.type())\n",
      "        if (materialization_macro is None):\n",
      "            missing_materialization(model, self.adapter.type())\n",
      "        if ('config' not in context):\n",
      "            raise InternalException('Invalid materialization context generated, missing config: {}'.format(context))\n",
      "        context_config = context['config']\n",
      "        hook_ctx = self.adapter.pre_model_hook(context_config)\n",
      "        try:\n",
      "            result = MacroGenerator(materialization_macro, context)()\n",
      "        finally:\n",
      "            self.adapter.post_model_hook(context_config, hook_ctx)\n",
      "        for relation in self._materialization_relations(result, model):\n",
      "            self.adapter.cache_added(relation.incorporate(dbt_created=True))\n",
      "        return self._build_run_model_result(model, context)\n",
      "\n",
      "class FreshnessRunner(BaseRunner):\n",
      "\n",
      "    def on_skip(self):\n",
      "        raise RuntimeException('Freshness: nodes cannot be skipped!')\n",
      "\n",
      "    def get_result_status(self, result):\n",
      "        if result.error:\n",
      "            return {'node_status': 'error', 'node_error': str(result.error)}\n",
      "        else:\n",
      "            return {'node_status': str(result.status)}\n",
      "\n",
      "    def before_execute(self):\n",
      "        description = 'freshness of {0.source_name}.{0.name}'.format(self.node)\n",
      "        dbt.ui.printer.print_start_line(description, self.node_index, self.num_nodes)\n",
      "\n",
      "    def after_execute(self, result):\n",
      "        dbt.ui.printer.print_freshness_result_line(result, self.node_index, self.num_nodes)\n",
      "\n",
      "    def _build_run_result(self, node, start_time, error, status, timing_info, skip=False, failed=None):\n",
      "        execution_time = (time.time() - start_time)\n",
      "        thread_id = threading.current_thread().name\n",
      "        if (status is not None):\n",
      "            status = status.lower()\n",
      "        return PartialResult(node=node, status=status, error=error, execution_time=execution_time, thread_id=thread_id, timing=timing_info)\n",
      "\n",
      "    def from_run_result(self, result, start_time, timing_info):\n",
      "        result.execution_time = (time.time() - start_time)\n",
      "        result.timing.extend(timing_info)\n",
      "        return result\n",
      "\n",
      "    def execute(self, compiled_node, manifest):\n",
      "        if (compiled_node.loaded_at_field is None):\n",
      "            raise InternalException('Got to execute for source freshness of a source that has no loaded_at_field!')\n",
      "        relation = self.adapter.Relation.create_from_source(compiled_node)\n",
      "        with self.adapter.connection_for(compiled_node):\n",
      "            self.adapter.clear_transaction()\n",
      "            freshness = self.adapter.calculate_freshness(relation, compiled_node.loaded_at_field, compiled_node.freshness.filter, manifest=manifest)\n",
      "        status = compiled_node.freshness.status(freshness['age'])\n",
      "        return SourceFreshnessResult(node=compiled_node, status=status, thread_id=threading.current_thread().name, **freshness)\n",
      "\n",
      "    def compile(self, manifest):\n",
      "        if (self.node.resource_type != NodeType.Source):\n",
      "            raise RuntimeException('fresnhess runner: got a non-Source')\n",
      "        return self.node\n",
      "\n",
      "class TestRunner(CompileRunner):\n",
      "\n",
      "    def describe_node(self):\n",
      "        node_name = self.node.name\n",
      "        return 'test {}'.format(node_name)\n",
      "\n",
      "    def print_result_line(self, result):\n",
      "        schema_name = self.node.schema\n",
      "        dbt.ui.printer.print_test_result_line(result, schema_name, self.node_index, self.num_nodes)\n",
      "\n",
      "    def print_start_line(self):\n",
      "        description = self.describe_node()\n",
      "        dbt.ui.printer.print_start_line(description, self.node_index, self.num_nodes)\n",
      "\n",
      "    def execute_test(self, test):\n",
      "        (res, table) = self.adapter.execute(test.wrapped_sql, auto_begin=True, fetch=True)\n",
      "        num_rows = len(table.rows)\n",
      "        if (num_rows != 1):\n",
      "            num_cols = len(table.columns)\n",
      "            dbt.exceptions.raise_compiler_error(f'Bad test {test.test_metadata.name}: Returned {num_rows} rows and {num_cols} cols but expected 1 row and 1 column')\n",
      "        return table[0][0]\n",
      "\n",
      "    def before_execute(self):\n",
      "        self.print_start_line()\n",
      "\n",
      "    def execute(self, test, manifest):\n",
      "        failed_rows = self.execute_test(test)\n",
      "        severity = test.config.severity.upper()\n",
      "        if (failed_rows == 0):\n",
      "            return RunModelResult(test, status=failed_rows)\n",
      "        elif ((severity == 'ERROR') or dbt.flags.WARN_ERROR):\n",
      "            return RunModelResult(test, status=failed_rows, fail=True)\n",
      "        else:\n",
      "            return RunModelResult(test, status=failed_rows, warn=True)\n",
      "\n",
      "    def after_execute(self, result):\n",
      "        self.print_result_line(result)\n",
      "\n",
      "class SnapshotRunner(ModelRunner):\n",
      "\n",
      "    def describe_node(self):\n",
      "        return 'snapshot {}'.format(self.get_node_representation())\n",
      "\n",
      "    def print_result_line(self, result):\n",
      "        dbt.ui.printer.print_snapshot_result_line(result, self.get_node_representation(), self.node_index, self.num_nodes)\n",
      "\n",
      "class SeedRunner(ModelRunner):\n",
      "\n",
      "    def describe_node(self):\n",
      "        return 'seed file {}'.format(self.get_node_representation())\n",
      "\n",
      "    def before_execute(self):\n",
      "        description = self.describe_node()\n",
      "        dbt.ui.printer.print_start_line(description, self.node_index, self.num_nodes)\n",
      "\n",
      "    def _build_run_model_result(self, model, context):\n",
      "        result = super()._build_run_model_result(model, context)\n",
      "        agate_result = context['load_result']('agate_table')\n",
      "        result.agate_table = agate_result.table\n",
      "        return result\n",
      "\n",
      "    def compile(self, manifest):\n",
      "        return self.node\n",
      "\n",
      "    def print_result_line(self, result):\n",
      "        schema_name = self.node.schema\n",
      "        dbt.ui.printer.print_seed_result_line(result, schema_name, self.node_index, self.num_nodes)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def match(function, returns):\n",
    "    return function.lineno == 74 and astunparse.unparse(returns).strip() == 'Any'\n",
    "print(astunparse.unparse(parsed_source))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6cc93d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "pdb on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "569def4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "599da509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1fdd10fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_source = ast.parse(source)\n",
    "clean_ast = TypeHintRemover(len(source), preserve_other_types=False, remove_type_imports=False).visit(parsed_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b89f431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a7713ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import abc\n",
      "import threading\n",
      "import time\n",
      "import traceback\n",
      "from typing import List, Dict, Any, Optional\n",
      "from dbt import deprecations\n",
      "from dbt.adapters.base import BaseRelation\n",
      "from dbt.clients.jinja import MacroGenerator\n",
      "from dbt.compilation import compile_node\n",
      "from dbt.context.providers import generate_runtime_model\n",
      "from dbt.contracts.graph.manifest import Manifest\n",
      "from dbt.contracts.results import RunModelResult, collect_timing_info, SourceFreshnessResult, PartialResult\n",
      "from dbt.exceptions import NotImplementedException, CompilationException, RuntimeException, InternalException, missing_materialization\n",
      "from dbt.logger import GLOBAL_LOGGER as logger\n",
      "from dbt.node_types import NodeType\n",
      "import dbt.exceptions\n",
      "import dbt.tracking\n",
      "import dbt.ui.printer\n",
      "import dbt.flags\n",
      "INTERNAL_ERROR_STRING = 'This is an error in dbt. Please try again. If the error persists, open an issue at https://github.com/fishtown-analytics/dbt\\n'.strip()\n",
      "\n",
      "def track_model_run(index, num_nodes, run_model_result):\n",
      "    if (dbt.tracking.active_user is None):\n",
      "        raise InternalException('cannot track model run with no active user')\n",
      "    invocation_id = dbt.tracking.active_user.invocation_id\n",
      "    dbt.tracking.track_model_run({'invocation_id': invocation_id, 'index': index, 'total': num_nodes, 'execution_time': run_model_result.execution_time, 'run_status': run_model_result.status, 'run_skipped': run_model_result.skip, 'run_error': None, 'model_materialization': run_model_result.node.get_materialization(), 'model_id': dbt.utils.get_hash(run_model_result.node), 'hashed_contents': dbt.utils.get_hashed_contents(run_model_result.node), 'timing': [t.to_dict() for t in run_model_result.timing]})\n",
      "\n",
      "class ExecutionContext():\n",
      "    'During execution and error handling, dbt makes use of mutable state:\\n    timing information and the newest (compiled vs executed) form of the node.\\n    '\n",
      "\n",
      "    def __init__(self, node):\n",
      "        self.timing = []\n",
      "        self.node = node\n",
      "\n",
      "class BaseRunner(metaclass=abc.ABCMeta):\n",
      "\n",
      "    def __init__(self, config, adapter, node, node_index, num_nodes):\n",
      "        self.config = config\n",
      "        self.adapter = adapter\n",
      "        self.node = node\n",
      "        self.node_index = node_index\n",
      "        self.num_nodes = num_nodes\n",
      "        self.skip = False\n",
      "        self.skip_cause: Optional[RunModelResult] = None\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def compile(self, manifest):\n",
      "        pass\n",
      "\n",
      "    def get_result_status(self, result):\n",
      "        if result.error:\n",
      "            return {'node_status': 'error', 'node_error': str(result.error)}\n",
      "        elif result.skip:\n",
      "            return {'node_status': 'skipped'}\n",
      "        elif result.fail:\n",
      "            return {'node_status': 'failed'}\n",
      "        elif result.warn:\n",
      "            return {'node_status': 'warn'}\n",
      "        else:\n",
      "            return {'node_status': 'passed'}\n",
      "\n",
      "    def run_with_hooks(self, manifest):\n",
      "        if self.skip:\n",
      "            return self.on_skip()\n",
      "        if (not self.node.is_ephemeral_model):\n",
      "            self.before_execute()\n",
      "        result = self.safe_run(manifest)\n",
      "        if (not self.node.is_ephemeral_model):\n",
      "            self.after_execute(result)\n",
      "        return result\n",
      "\n",
      "    def _build_run_result(self, node, start_time, error, status, timing_info, skip=False, fail=None, warn=None, agate_table=None):\n",
      "        execution_time = (time.time() - start_time)\n",
      "        thread_id = threading.current_thread().name\n",
      "        return RunModelResult(node=node, error=error, skip=skip, status=status, fail=fail, warn=warn, execution_time=execution_time, thread_id=thread_id, timing=timing_info, agate_table=agate_table)\n",
      "\n",
      "    def error_result(self, node, error, start_time, timing_info):\n",
      "        return self._build_run_result(node=node, start_time=start_time, error=error, status='ERROR', timing_info=timing_info)\n",
      "\n",
      "    def ephemeral_result(self, node, start_time, timing_info):\n",
      "        return self._build_run_result(node=node, start_time=start_time, error=None, status=None, timing_info=timing_info)\n",
      "\n",
      "    def from_run_result(self, result, start_time, timing_info):\n",
      "        return self._build_run_result(node=result.node, start_time=start_time, error=result.error, skip=result.skip, status=result.status, fail=result.fail, warn=result.warn, timing_info=timing_info, agate_table=result.agate_table)\n",
      "\n",
      "    def compile_and_execute(self, manifest, ctx):\n",
      "        result = None\n",
      "        with self.adapter.connection_for(self.node):\n",
      "            with collect_timing_info('compile') as timing_info:\n",
      "                ctx.node = self.compile(manifest)\n",
      "            ctx.timing.append(timing_info)\n",
      "            if (not ctx.node.is_ephemeral_model):\n",
      "                with collect_timing_info('execute') as timing_info:\n",
      "                    result = self.run(ctx.node, manifest)\n",
      "                    ctx.node = result.node\n",
      "                ctx.timing.append(timing_info)\n",
      "        return result\n",
      "\n",
      "    def _handle_catchable_exception(self, e, ctx):\n",
      "        if (e.node is None):\n",
      "            e.node = ctx.node\n",
      "        logger.debug(str(e), exc_info=True)\n",
      "        return str(e)\n",
      "\n",
      "    def _handle_internal_exception(self, e, ctx):\n",
      "        build_path = self.node.build_path\n",
      "        prefix = 'Internal error executing {}'.format(build_path)\n",
      "        error = '{prefix}\\n{error}\\n\\n{note}'.format(prefix=dbt.ui.printer.red(prefix), error=str(e).strip(), note=INTERNAL_ERROR_STRING)\n",
      "        logger.debug(error, exc_info=True)\n",
      "        return str(e)\n",
      "\n",
      "    def _handle_generic_exception(self, e, ctx):\n",
      "        node_description = self.node.build_path\n",
      "        if (node_description is None):\n",
      "            node_description = self.node.unique_id\n",
      "        prefix = 'Unhandled error while executing {}'.format(node_description)\n",
      "        error = '{prefix}\\n{error}'.format(prefix=dbt.ui.printer.red(prefix), error=str(e).strip())\n",
      "        logger.error(error)\n",
      "        logger.debug('', exc_info=True)\n",
      "        return str(e)\n",
      "\n",
      "    def handle_exception(self, e, ctx):\n",
      "        catchable_errors = (CompilationException, RuntimeException)\n",
      "        if isinstance(e, catchable_errors):\n",
      "            error = self._handle_catchable_exception(e, ctx)\n",
      "        elif isinstance(e, InternalException):\n",
      "            error = self._handle_internal_exception(e, ctx)\n",
      "        else:\n",
      "            error = self._handle_generic_exception(e, ctx)\n",
      "        return error\n",
      "\n",
      "    def safe_run(self, manifest):\n",
      "        started = time.time()\n",
      "        ctx = ExecutionContext(self.node)\n",
      "        error = None\n",
      "        result = None\n",
      "        try:\n",
      "            result = self.compile_and_execute(manifest, ctx)\n",
      "        except Exception as e:\n",
      "            error = self.handle_exception(e, ctx)\n",
      "        finally:\n",
      "            exc_str = self._safe_release_connection()\n",
      "            if ((exc_str is not None) and (result is not None) and (result.error is None) and (error is None)):\n",
      "                error = exc_str\n",
      "        if (error is not None):\n",
      "            result = self.error_result(ctx.node, error, started, [])\n",
      "        elif (result is not None):\n",
      "            result = self.from_run_result(result, started, ctx.timing)\n",
      "        else:\n",
      "            result = self.ephemeral_result(ctx.node, started, ctx.timing)\n",
      "        return result\n",
      "\n",
      "    def _safe_release_connection(self):\n",
      "        'Try to release a connection. If an exception is hit, log and return\\n        the error string.\\n        '\n",
      "        try:\n",
      "            self.adapter.release_connection()\n",
      "        except Exception as exc:\n",
      "            logger.debug('Error releasing connection for node {}: {!s}\\n{}'.format(self.node.name, exc, traceback.format_exc()))\n",
      "            return str(exc)\n",
      "        return None\n",
      "\n",
      "    def before_execute(self):\n",
      "        raise NotImplementedException()\n",
      "\n",
      "    def execute(self, compiled_node, manifest):\n",
      "        raise NotImplementedException()\n",
      "\n",
      "    def run(self, compiled_node, manifest):\n",
      "        return self.execute(compiled_node, manifest)\n",
      "\n",
      "    def after_execute(self, result):\n",
      "        raise NotImplementedException()\n",
      "\n",
      "    def _skip_caused_by_ephemeral_failure(self):\n",
      "        if ((self.skip_cause is None) or (self.skip_cause.node is None)):\n",
      "            return False\n",
      "        return self.skip_cause.node.is_ephemeral_model\n",
      "\n",
      "    def on_skip(self):\n",
      "        schema_name = self.node.schema\n",
      "        node_name = self.node.name\n",
      "        error = None\n",
      "        if (not self.node.is_ephemeral_model):\n",
      "            if self._skip_caused_by_ephemeral_failure():\n",
      "                dbt.ui.printer.print_skip_caused_by_error(self.node, schema_name, node_name, self.node_index, self.num_nodes, self.skip_cause)\n",
      "                if (self.skip_cause is None):\n",
      "                    raise InternalException('Skip cause not set but skip was somehow caused by an ephemeral failure')\n",
      "                error = 'Compilation Error in {}, caused by compilation error in referenced ephemeral model {}'.format(self.node.unique_id, self.skip_cause.node.unique_id)\n",
      "            else:\n",
      "                dbt.ui.printer.print_skip_line(self.node, schema_name, node_name, self.node_index, self.num_nodes)\n",
      "        node_result = RunModelResult(self.node, skip=True, error=error)\n",
      "        return node_result\n",
      "\n",
      "    def do_skip(self, cause=None):\n",
      "        self.skip = True\n",
      "        self.skip_cause = cause\n",
      "\n",
      "class CompileRunner(BaseRunner):\n",
      "\n",
      "    def before_execute(self):\n",
      "        pass\n",
      "\n",
      "    def after_execute(self, result):\n",
      "        pass\n",
      "\n",
      "    def execute(self, compiled_node, manifest):\n",
      "        return RunModelResult(compiled_node)\n",
      "\n",
      "    def compile(self, manifest):\n",
      "        return compile_node(self.adapter, self.config, self.node, manifest, {})\n",
      "\n",
      "def _validate_materialization_relations_dict(inp, model):\n",
      "    try:\n",
      "        relations_value = inp['relations']\n",
      "    except KeyError:\n",
      "        msg = 'Invalid return value from materialization, \"relations\" not found, got keys: {}'.format(list(inp))\n",
      "        raise CompilationException(msg, node=model) from None\n",
      "    if (not isinstance(relations_value, list)):\n",
      "        msg = 'Invalid return value from materialization, \"relations\" not a list, got: {}'.format(relations_value)\n",
      "        raise CompilationException(msg, node=model) from None\n",
      "    relations: List[BaseRelation] = []\n",
      "    for relation in relations_value:\n",
      "        if (not isinstance(relation, BaseRelation)):\n",
      "            msg = 'Invalid return value from materialization, \"relations\" contains non-Relation: {}'.format(relation)\n",
      "            raise CompilationException(msg, node=model)\n",
      "        assert isinstance(relation, BaseRelation)\n",
      "        relations.append(relation)\n",
      "    return relations\n",
      "\n",
      "class ModelRunner(CompileRunner):\n",
      "\n",
      "    def get_node_representation(self):\n",
      "        if (self.config.credentials.database == self.node.database):\n",
      "            template = '{0.schema}.{0.alias}'\n",
      "        else:\n",
      "            template = '{0.database}.{0.schema}.{0.alias}'\n",
      "        return template.format(self.node)\n",
      "\n",
      "    def describe_node(self):\n",
      "        return '{} model {}'.format(self.node.get_materialization(), self.get_node_representation())\n",
      "\n",
      "    def print_start_line(self):\n",
      "        description = self.describe_node()\n",
      "        dbt.ui.printer.print_start_line(description, self.node_index, self.num_nodes)\n",
      "\n",
      "    def print_result_line(self, result):\n",
      "        description = self.describe_node()\n",
      "        dbt.ui.printer.print_model_result_line(result, description, self.node_index, self.num_nodes)\n",
      "\n",
      "    def before_execute(self):\n",
      "        self.print_start_line()\n",
      "\n",
      "    def after_execute(self, result):\n",
      "        track_model_run(self.node_index, self.num_nodes, result)\n",
      "        self.print_result_line(result)\n",
      "\n",
      "    def _build_run_model_result(self, model, context):\n",
      "        result = context['load_result']('main')\n",
      "        return RunModelResult(model, status=result.status)\n",
      "\n",
      "    def _materialization_relations(self, result, model):\n",
      "        if isinstance(result, str):\n",
      "            deprecations.warn('materialization-return', materialization=model.get_materialization())\n",
      "            return [self.adapter.Relation.create_from(self.config, model)]\n",
      "        if isinstance(result, dict):\n",
      "            return _validate_materialization_relations_dict(result, model)\n",
      "        msg = 'Invalid return value from materialization, expected a dict with key \"relations\", got: {}'.format(str(result))\n",
      "        raise CompilationException(msg, node=model)\n",
      "\n",
      "    def execute(self, model, manifest):\n",
      "        context = generate_runtime_model(model, self.config, manifest)\n",
      "        materialization_macro = manifest.find_materialization_macro_by_name(self.config.project_name, model.get_materialization(), self.adapter.type())\n",
      "        if (materialization_macro is None):\n",
      "            missing_materialization(model, self.adapter.type())\n",
      "        if ('config' not in context):\n",
      "            raise InternalException('Invalid materialization context generated, missing config: {}'.format(context))\n",
      "        context_config = context['config']\n",
      "        hook_ctx = self.adapter.pre_model_hook(context_config)\n",
      "        try:\n",
      "            result = MacroGenerator(materialization_macro, context)()\n",
      "        finally:\n",
      "            self.adapter.post_model_hook(context_config, hook_ctx)\n",
      "        for relation in self._materialization_relations(result, model):\n",
      "            self.adapter.cache_added(relation.incorporate(dbt_created=True))\n",
      "        return self._build_run_model_result(model, context)\n",
      "\n",
      "class FreshnessRunner(BaseRunner):\n",
      "\n",
      "    def on_skip(self):\n",
      "        raise RuntimeException('Freshness: nodes cannot be skipped!')\n",
      "\n",
      "    def get_result_status(self, result):\n",
      "        if result.error:\n",
      "            return {'node_status': 'error', 'node_error': str(result.error)}\n",
      "        else:\n",
      "            return {'node_status': str(result.status)}\n",
      "\n",
      "    def before_execute(self):\n",
      "        description = 'freshness of {0.source_name}.{0.name}'.format(self.node)\n",
      "        dbt.ui.printer.print_start_line(description, self.node_index, self.num_nodes)\n",
      "\n",
      "    def after_execute(self, result):\n",
      "        dbt.ui.printer.print_freshness_result_line(result, self.node_index, self.num_nodes)\n",
      "\n",
      "    def _build_run_result(self, node, start_time, error, status, timing_info, skip=False, failed=None):\n",
      "        execution_time = (time.time() - start_time)\n",
      "        thread_id = threading.current_thread().name\n",
      "        if (status is not None):\n",
      "            status = status.lower()\n",
      "        return PartialResult(node=node, status=status, error=error, execution_time=execution_time, thread_id=thread_id, timing=timing_info)\n",
      "\n",
      "    def from_run_result(self, result, start_time, timing_info):\n",
      "        result.execution_time = (time.time() - start_time)\n",
      "        result.timing.extend(timing_info)\n",
      "        return result\n",
      "\n",
      "    def execute(self, compiled_node, manifest):\n",
      "        if (compiled_node.loaded_at_field is None):\n",
      "            raise InternalException('Got to execute for source freshness of a source that has no loaded_at_field!')\n",
      "        relation = self.adapter.Relation.create_from_source(compiled_node)\n",
      "        with self.adapter.connection_for(compiled_node):\n",
      "            self.adapter.clear_transaction()\n",
      "            freshness = self.adapter.calculate_freshness(relation, compiled_node.loaded_at_field, compiled_node.freshness.filter, manifest=manifest)\n",
      "        status = compiled_node.freshness.status(freshness['age'])\n",
      "        return SourceFreshnessResult(node=compiled_node, status=status, thread_id=threading.current_thread().name, **freshness)\n",
      "\n",
      "    def compile(self, manifest):\n",
      "        if (self.node.resource_type != NodeType.Source):\n",
      "            raise RuntimeException('fresnhess runner: got a non-Source')\n",
      "        return self.node\n",
      "\n",
      "class TestRunner(CompileRunner):\n",
      "\n",
      "    def describe_node(self):\n",
      "        node_name = self.node.name\n",
      "        return 'test {}'.format(node_name)\n",
      "\n",
      "    def print_result_line(self, result):\n",
      "        schema_name = self.node.schema\n",
      "        dbt.ui.printer.print_test_result_line(result, schema_name, self.node_index, self.num_nodes)\n",
      "\n",
      "    def print_start_line(self):\n",
      "        description = self.describe_node()\n",
      "        dbt.ui.printer.print_start_line(description, self.node_index, self.num_nodes)\n",
      "\n",
      "    def execute_test(self, test):\n",
      "        (res, table) = self.adapter.execute(test.wrapped_sql, auto_begin=True, fetch=True)\n",
      "        num_rows = len(table.rows)\n",
      "        if (num_rows != 1):\n",
      "            num_cols = len(table.columns)\n",
      "            dbt.exceptions.raise_compiler_error(f'Bad test {test.test_metadata.name}: Returned {num_rows} rows and {num_cols} cols but expected 1 row and 1 column')\n",
      "        return table[0][0]\n",
      "\n",
      "    def before_execute(self):\n",
      "        self.print_start_line()\n",
      "\n",
      "    def execute(self, test, manifest):\n",
      "        failed_rows = self.execute_test(test)\n",
      "        severity = test.config.severity.upper()\n",
      "        if (failed_rows == 0):\n",
      "            return RunModelResult(test, status=failed_rows)\n",
      "        elif ((severity == 'ERROR') or dbt.flags.WARN_ERROR):\n",
      "            return RunModelResult(test, status=failed_rows, fail=True)\n",
      "        else:\n",
      "            return RunModelResult(test, status=failed_rows, warn=True)\n",
      "\n",
      "    def after_execute(self, result):\n",
      "        self.print_result_line(result)\n",
      "\n",
      "class SnapshotRunner(ModelRunner):\n",
      "\n",
      "    def describe_node(self):\n",
      "        return 'snapshot {}'.format(self.get_node_representation())\n",
      "\n",
      "    def print_result_line(self, result):\n",
      "        dbt.ui.printer.print_snapshot_result_line(result, self.get_node_representation(), self.node_index, self.num_nodes)\n",
      "\n",
      "class SeedRunner(ModelRunner):\n",
      "\n",
      "    def describe_node(self):\n",
      "        return 'seed file {}'.format(self.get_node_representation())\n",
      "\n",
      "    def before_execute(self):\n",
      "        description = self.describe_node()\n",
      "        dbt.ui.printer.print_start_line(description, self.node_index, self.num_nodes)\n",
      "\n",
      "    def _build_run_model_result(self, model, context):\n",
      "        result = super()._build_run_model_result(model, context)\n",
      "        agate_result = context['load_result']('agate_table')\n",
      "        result.agate_table = agate_result.table\n",
      "        return result\n",
      "\n",
      "    def compile(self, manifest):\n",
      "        return self.node\n",
      "\n",
      "    def print_result_line(self, result):\n",
      "        schema_name = self.node.schema\n",
      "        dbt.ui.printer.print_seed_result_line(result, schema_name, self.node_index, self.num_nodes)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(astunparse.unparse(clean_ast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2ada964d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['    def _build_run_result(self, node, start_time, error, status, timing_info, skip=False, fail=None, warn=None, agate_table=None):',\n",
       " '        execution_time = (time.time() - start_time)',\n",
       " '        thread_id = threading.current_thread().name',\n",
       " '        return RunModelResult(node=node, error=error, skip=skip, status=status, fail=fail, warn=warn, execution_time=execution_time, thread_id=thread_id, timing=timing_info, agate_table=agate_table)']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "astunparse.unparse(clean_ast).splitlines()[72:76]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7ebc2f4d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2182391/3238659631.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0munique\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mparsed_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtransformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTypeHintRemover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_other_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_type_imports\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtransformed_ast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/codex/lib/python3.7/ast.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(source, filename, mode)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mEquivalent\u001b[0m \u001b[0mto\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPyCF_ONLY_AST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \"\"\"\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPyCF_ONLY_AST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/private/home/dpf/.conda/envs/codex/lib/python3.7/ast.py\u001b[0m(35)\u001b[0;36mparse\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     33 \u001b[0;31m    \u001b[0mEquivalent\u001b[0m \u001b[0mto\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPyCF_ONLY_AST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     34 \u001b[0;31m    \"\"\"\n",
      "\u001b[0m\u001b[0;32m---> 35 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPyCF_ONLY_AST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     36 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     37 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "parsed_source = ast.parse(source)\n",
    "clean_source = astunparse.unparse(TypeHintRemover(len(source), preserve_other_types=False, remove_type_imports=False).visit(ast.parse(source)))\n",
    "unique = set()\n",
    "for i in range(len(source)):\n",
    "    parsed_source = ast.parse(source)\n",
    "    transformer = TypeHintRemover(i, preserve_other_types=False, remove_type_imports=False)\n",
    "    transformed_ast = transformer.visit(parsed_source)\n",
    "    transformed = astunparse.unparse(transformed_ast)\n",
    "    if transformer.guard_value is not None:\n",
    "        unique.add((transformed, transformed_ast, transformer.guard_value, transformer.guard_node))\n",
    "infills = []\n",
    "for (removed_source, removed_ast, removed_value, removed_node) in unique:\n",
    "    if removed_value is None:\n",
    "        continue\n",
    "    for left, right in derive_prefix_suffix(clean_source, removed_value.strip()):\n",
    "#         print(\"left:\", left)\n",
    "#         print(\"right:\", right)\n",
    "#         print(\"removed:\", removed_value)\n",
    "        infills.append((left,right,removed_value))\n",
    "# pprint.pprint(infills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8adfa8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found it\n"
     ]
    }
   ],
   "source": [
    "# for transformed, transformed_ast, value, node in unique:\n",
    "#     if node.lineno == 20 and value.strip() == 'PlayerID':\n",
    "#         print(\"found it\")\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cc900f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# content = '''\n",
    "# \"\"\"Type used for pivot coll for basic game model training\"\"\"\n",
    "# from default_imports import *\n",
    "\n",
    "# from modules.game.Game import GameID, PlayerID\n",
    "\n",
    "# from pymongo.collection import Collection\n",
    "\n",
    "# BasicGameActivationID = NewType('BasicGameActivationID', str)\n",
    "# Prediction = NewType('Prediction', int)\n",
    "\n",
    "# class BasicGameActivation(NamedTuple('BasicGameActivation', [\n",
    "#         ('id', BasicGameActivationID),\n",
    "#         ('gameId', GameID),\n",
    "#         ('playerId', PlayerID),\n",
    "#         ('engine', bool),\n",
    "#         ('prediction', int)\n",
    "#     ])):\n",
    "#     @staticmethod\n",
    "#     def fromPrediction(gameId: GameID, playerId: PlayerID, prediction: Prediction, engine: bool):\n",
    "#         return BasicGameActivation(\n",
    "#             id = gameId + '/' + playerId,\n",
    "#             gameId = gameId,\n",
    "#             playerId = playerId,\n",
    "#             engine = engine,\n",
    "#             prediction = prediction\n",
    "#             )\n",
    "\n",
    "#     @staticmethod\n",
    "#     def makeId(gameId: GameID, playerId: PlayerID) -> BasicGameActivationID:\n",
    "#         return gameId + '/' + playerId\n",
    "\n",
    "# class BasicGameActivationBSONHandler:\n",
    "#     @staticmethod\n",
    "#     def reads(bson: Dict) -> BasicGameActivation:\n",
    "#         return BasicGameActivation(\n",
    "#             id = bson['_id'],\n",
    "#             gameId = bson['gameId'],\n",
    "#             playerId = bson['userId'],\n",
    "#             engine = bson['engine'],\n",
    "#             prediction = bson['prediction'])\n",
    "\n",
    "#     @staticmethod\n",
    "#     def writes(gba: BasicGameActivation) -> Dict:\n",
    "#         return {\n",
    "#             '_id': gba.id,\n",
    "#             'gameId': gba.gameId,\n",
    "#             'userId': gba.playerId,\n",
    "#             'engine': gba.engine,\n",
    "#             'prediction': gba.prediction\n",
    "#         }\n",
    "\n",
    "# class BasicGameActivationDB(NamedTuple('BasicGameActivationDB', [\n",
    "#         ('basicGameActivationColl', Collection)\n",
    "#     ])):\n",
    "#     def byPlayerId(self, playerId: PlayerID) -> List[BasicGameActivation]:\n",
    "#         return [BasicGameActivationBSONHandler.reads(bson) for bson in self.basicGameActivationColl.find({'userId': playerId})]\n",
    "\n",
    "#     def byEngineAndPrediction(self, engine: bool, prediction: Prediction, limit: Opt[int] = None) -> List[BasicGameActivation]:\n",
    "#         gtlt = '$gte' if engine else '$lte'\n",
    "#         pipeline = [{'$match': {'engine': engine, 'prediction': {gtlt: prediction}}}]\n",
    "\n",
    "#         if limit is not None:\n",
    "#             pipeline.append({'$sample': {'size': limit}})\n",
    "\n",
    "#         return [BasicGameActivationBSONHandler.reads(bson) for bson in self.basicGameActivationColl.aggregate(pipeline)]\n",
    "\n",
    "#     def write(self, gba: BasicGameActivation):\n",
    "#         self.basicGameActivationColl.update_one({'_id': gba.id}, {'$set': BasicGameActivationBSONHandler.writes(gba)}, upsert=True)\n",
    "\n",
    "#     def writeMany(self, gbas: List[BasicGameActivation]):\n",
    "#         [self.write(gba) for gba in gbas]\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b8b7999e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node.lineno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a6c618d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node.col_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f713abaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'Type used for pivot coll for basic game model training'\n",
      "from default_imports import *\n",
      "from modules.game.Game import GameID, PlayerID\n",
      "from pymongo.collection import Collection\n",
      "BasicGameActivationID = NewType('BasicGameActivationID', str)\n",
      "Prediction = NewType('Prediction', int)\n",
      "\n",
      "class BasicGameActivation(NamedTuple('BasicGameActivation', [('id', BasicGameActivationID), ('gameId', GameID), ('playerId', PlayerID), ('engine', bool), ('prediction', int)])):\n",
      "\n",
      "    @staticmethod\n",
      "    def fromPrediction(gameId, playerId, prediction, engine):\n",
      "        return BasicGameActivation(id=((gameId + '/') + playerId), gameId=gameId, playerId=playerId, engine=engine, prediction=prediction)\n",
      "\n",
      "    @staticmethod\n",
      "    def makeId(gameId, playerId):\n",
      "        return ((gameId + '/') + playerId)\n",
      "\n",
      "class BasicGameActivationBSONHandler():\n",
      "\n",
      "    @staticmethod\n",
      "    def reads(bson):\n",
      "        return BasicGameActivation(id=bson['_id'], gameId=bson['gameId'], playerId=bson['userId'], engine=bson['engine'], prediction=bson['prediction'])\n",
      "\n",
      "    @staticmethod\n",
      "    def writes(gba):\n",
      "        return {'_id': gba.id, 'gameId': gba.gameId, 'userId': gba.playerId, 'engine': gba.engine, 'prediction': gba.prediction}\n",
      "\n",
      "class BasicGameActivationDB(NamedTuple('BasicGameActivationDB', [('basicGameActivationColl', Collection)])):\n",
      "\n",
      "    def byPlayerId(self, playerId):\n",
      "        return [BasicGameActivationBSONHandler.reads(bson) for bson in self.basicGameActivationColl.find({'userId': playerId})]\n",
      "\n",
      "    def byEngineAndPrediction(self, engine, prediction, limit=None):\n",
      "        gtlt = ('$gte' if engine else '$lte')\n",
      "        pipeline = [{'$match': {'engine': engine, 'prediction': {gtlt: prediction}}}]\n",
      "        if (limit is not None):\n",
      "            pipeline.append({'$sample': {'size': limit}})\n",
      "        return [BasicGameActivationBSONHandler.reads(bson) for bson in self.basicGameActivationColl.aggregate(pipeline)]\n",
      "\n",
      "    def write(self, gba):\n",
      "        self.basicGameActivationColl.update_one({'_id': gba.id}, {'$set': BasicGameActivationBSONHandler.writes(gba)}, upsert=True)\n",
      "\n",
      "    def writeMany(self, gbas):\n",
      "        [self.write(gba) for gba in gbas]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "39d30983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['List[BasicGameActivation]\\n',\n",
       " 'GameID\\n',\n",
       " 'BasicGameActivation\\n',\n",
       " 'List[BasicGameActivation]\\n',\n",
       " 'Opt[int]\\n',\n",
       " 'PlayerID\\n',\n",
       " 'PlayerID\\n',\n",
       " 'PlayerID\\n',\n",
       " 'GameID\\n',\n",
       " 'BasicGameActivation\\n',\n",
       " 'Dict\\n',\n",
       " 'bool\\n',\n",
       " 'Dict\\n',\n",
       " 'Prediction\\n',\n",
       " 'Prediction\\n',\n",
       " 'BasicGameActivation\\n',\n",
       " 'bool\\n',\n",
       " 'List[BasicGameActivation]\\n',\n",
       " 'BasicGameActivationID\\n']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t[2] for t in unique]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9272888a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_ast.Name object at 0x7f084e9c9b90>\n"
     ]
    }
   ],
   "source": [
    "print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e0dede18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GameID\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fe2109c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node.lineno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "aba7b86b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node.col_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ff3345ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'Type used for pivot coll for basic game model training'\n",
      "from default_imports import *\n",
      "from modules.game.Game import GameID, PlayerID\n",
      "from pymongo.collection import Collection\n",
      "BasicGameActivationID = NewType('BasicGameActivationID', str)\n",
      "Prediction = NewType('Prediction', int)\n",
      "\n",
      "class BasicGameActivation(NamedTuple('BasicGameActivation', [('id', BasicGameActivationID), ('gameId', GameID), ('playerId', PlayerID), ('engine', bool), ('prediction', int)])):\n",
      "\n",
      "    @staticmethod\n",
      "    def fromPrediction(gameId, playerId, prediction, engine):\n",
      "        return BasicGameActivation(id=((gameId + '/') + playerId), gameId=gameId, playerId=playerId, engine=engine, prediction=prediction)\n",
      "\n",
      "    @staticmethod\n",
      "    def makeId(gameId, playerId):\n",
      "        return ((gameId + '/') + playerId)\n",
      "\n",
      "class BasicGameActivationBSONHandler():\n",
      "\n",
      "    @staticmethod\n",
      "    def reads(bson):\n",
      "        return BasicGameActivation(id=bson['_id'], gameId=bson['gameId'], playerId=bson['userId'], engine=bson['engine'], prediction=bson['prediction'])\n",
      "\n",
      "    @staticmethod\n",
      "    def writes(gba):\n",
      "        return {'_id': gba.id, 'gameId': gba.gameId, 'userId': gba.playerId, 'engine': gba.engine, 'prediction': gba.prediction}\n",
      "\n",
      "class BasicGameActivationDB(NamedTuple('BasicGameActivationDB', [('basicGameActivationColl', Collection)])):\n",
      "\n",
      "    def byPlayerId(self, playerId):\n",
      "        return [BasicGameActivationBSONHandler.reads(bson) for bson in self.basicGameActivationColl.find({'userId': playerId})]\n",
      "\n",
      "    def byEngineAndPrediction(self, engine, prediction, limit=None):\n",
      "        gtlt = ('$gte' if engine else '$lte')\n",
      "        pipeline = [{'$match': {'engine': engine, 'prediction': {gtlt: prediction}}}]\n",
      "        if (limit is not None):\n",
      "            pipeline.append({'$sample': {'size': limit}})\n",
      "        return [BasicGameActivationBSONHandler.reads(bson) for bson in self.basicGameActivationColl.aggregate(pipeline)]\n",
      "\n",
      "    def write(self, gba):\n",
      "        self.basicGameActivationColl.update_one({'_id': gba.id}, {'$set': BasicGameActivationBSONHandler.writes(gba)}, upsert=True)\n",
      "\n",
      "    def writeMany(self, gbas):\n",
      "        [self.write(gba) for gba in gbas]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1b170681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bool\\n'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "da67fbae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node.lineno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b16338f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node.col_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4516a19a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_ast.Load at 0x7f084b686c90>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node.ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2efeb722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_ast.Module at 0x7f084b6ab990>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "90814ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'Type used for pivot coll for basic game model training'\n",
      "from default_imports import *\n",
      "from modules.game.Game import GameID, PlayerID\n",
      "from pymongo.collection import Collection\n",
      "BasicGameActivationID = NewType('BasicGameActivationID', str)\n",
      "Prediction = NewType('Prediction', int)\n",
      "\n",
      "class BasicGameActivation(NamedTuple('BasicGameActivation', [('id', BasicGameActivationID), ('gameId', GameID), ('playerId', PlayerID), ('engine', bool), ('prediction', int)])):\n",
      "\n",
      "    @staticmethod\n",
      "    def fromPrediction(gameId, playerId: PlayerID, prediction, engine: bool):\n",
      "        return BasicGameActivation(id=((gameId + '/') + playerId), gameId=gameId, playerId=playerId, engine=engine, prediction=prediction)\n",
      "\n",
      "    @staticmethod\n",
      "    def makeId(gameId: GameID, playerId):\n",
      "        return ((gameId + '/') + playerId)\n",
      "\n",
      "class BasicGameActivationBSONHandler():\n",
      "\n",
      "    @staticmethod\n",
      "    def reads(bson) -> BasicGameActivation:\n",
      "        return BasicGameActivation(id=bson['_id'], gameId=bson['gameId'], playerId=bson['userId'], engine=bson['engine'], prediction=bson['prediction'])\n",
      "\n",
      "    @staticmethod\n",
      "    def writes(gba) -> Dict:\n",
      "        return {'_id': gba.id, 'gameId': gba.gameId, 'userId': gba.playerId, 'engine': gba.engine, 'prediction': gba.prediction}\n",
      "\n",
      "class BasicGameActivationDB(NamedTuple('BasicGameActivationDB', [('basicGameActivationColl', Collection)])):\n",
      "\n",
      "    def byPlayerId(self, playerId) -> List[BasicGameActivation]:\n",
      "        return [BasicGameActivationBSONHandler.reads(bson) for bson in self.basicGameActivationColl.find({'userId': playerId})]\n",
      "\n",
      "    def byEngineAndPrediction(self, engine, prediction: Prediction, limit: Opt[int]=None) -> List[BasicGameActivation]:\n",
      "        gtlt = ('$gte' if engine else '$lte')\n",
      "        pipeline = [{'$match': {'engine': engine, 'prediction': {gtlt: prediction}}}]\n",
      "        if (limit is not None):\n",
      "            pipeline.append({'$sample': {'size': limit}})\n",
      "        return [BasicGameActivationBSONHandler.reads(bson) for bson in self.basicGameActivationColl.aggregate(pipeline)]\n",
      "\n",
      "    def write(self, gba: BasicGameActivation):\n",
      "        self.basicGameActivationColl.update_one({'_id': gba.id}, {'$set': BasicGameActivationBSONHandler.writes(gba)}, upsert=True)\n",
      "\n",
      "    def writeMany(self, gbas: List[BasicGameActivation]):\n",
      "        [self.write(gba) for gba in gbas]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e55bf379",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.guard_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2d969c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "006188b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'Type used for pivot coll for basic game model training'\n",
      "from default_imports import *\n",
      "from modules.game.Game import GameID, PlayerID\n",
      "from pymongo.collection import Collection\n",
      "BasicGameActivationID = NewType('BasicGameActivationID', str)\n",
      "Prediction = NewType('Prediction', int)\n",
      "\n",
      "class BasicGameActivation(NamedTuple('BasicGameActivation', [('id', BasicGameActivationID), ('gameId', GameID), ('playerId', PlayerID), ('engine', bool), ('prediction', int)])):\n",
      "\n",
      "    @staticmethod\n",
      "    def fromPrediction(gameId, playerId: PlayerID, prediction, engine: bool):\n",
      "        return BasicGameActivation(id=((gameId + '/') + playerId), gameId=gameId, playerId=playerId, engine=engine, prediction=prediction)\n",
      "\n",
      "    @staticmethod\n",
      "    def makeId(gameId: GameID, playerId):\n",
      "        return ((gameId + '/') + playerId)\n",
      "\n",
      "class BasicGameActivationBSONHandler():\n",
      "\n",
      "    @staticmethod\n",
      "    def reads(bson) -> BasicGameActivation:\n",
      "        return BasicGameActivation(id=bson['_id'], gameId=bson['gameId'], playerId=bson['userId'], engine=bson['engine'], prediction=bson['prediction'])\n",
      "\n",
      "    @staticmethod\n",
      "    def writes(gba) -> Dict:\n",
      "        return {'_id': gba.id, 'gameId': gba.gameId, 'userId': gba.playerId, 'engine': gba.engine, 'prediction': gba.prediction}\n",
      "\n",
      "class BasicGameActivationDB(NamedTuple('BasicGameActivationDB', [('basicGameActivationColl', Collection)])):\n",
      "\n",
      "    def byPlayerId(self, playerId) -> List[BasicGameActivation]:\n",
      "        return [BasicGameActivationBSONHandler.reads(bson) for bson in self.basicGameActivationColl.find({'userId': playerId})]\n",
      "\n",
      "    def byEngineAndPrediction(self, engine, prediction: Prediction, limit=None) -> List[BasicGameActivation]:\n",
      "        gtlt = ('$gte' if engine else '$lte')\n",
      "        pipeline = [{'$match': {'engine': engine, 'prediction': {gtlt: prediction}}}]\n",
      "        if (limit is not None):\n",
      "            pipeline.append({'$sample': {'size': limit}})\n",
      "        return [BasicGameActivationBSONHandler.reads(bson) for bson in self.basicGameActivationColl.aggregate(pipeline)]\n",
      "\n",
      "    def write(self, gba: BasicGameActivation):\n",
      "        self.basicGameActivationColl.update_one({'_id': gba.id}, {'$set': BasicGameActivationBSONHandler.writes(gba)}, upsert=True)\n",
      "\n",
      "    def writeMany(self, gbas):\n",
      "        [self.write(gba) for gba in gbas]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67190cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
