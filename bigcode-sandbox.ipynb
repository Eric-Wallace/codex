{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddc3f9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdda49d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models import BigCodeModel, add_model_args, add_infilling_args\n",
    "# import argparse\n",
    "# parser = argparse.ArgumentParser()\n",
    "# add_model_args(parser)\n",
    "# add_infilling_args(parser)\n",
    "\n",
    "# args = parser.parse_args([])\n",
    "# model = BigCodeModel(args, \"bigcode/large-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d484716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.infill([\"def read_file(filename):\\n   \\\"\\\"\\\"\", \"\\\"\\\"\\\"\\n    with open(filename, 'r') as f:\\n        return f.read()\"], stop_words=None, truncation_parameters=None, temperature=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "715c979a",
   "metadata": {},
   "outputs": [],
   "source": [
    "END_OF_TEXT = \"<|endoftext|>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e0b267b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_NAME = \"bigcode/large-model\"\n",
    "# FIM_PREFIX = \"<fim_prefix>\"\n",
    "# FIM_SUFFIX = \"<fim_suffix>\"\n",
    "# FIM_MIDDLE = \"<fim_middle>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c244c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"bigcode/santacoder\"\n",
    "FIM_PREFIX = \"<fim-prefix>\"\n",
    "FIM_SUFFIX = \"<fim-suffix>\"\n",
    "FIM_MIDDLE = \"<fim-middle>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e92df63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, torch_dtype=torch.float16, trust_remote_code=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b18f440a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete(text, **kwargs):\n",
    "    encoded = tokenizer.batch_encode_plus([text], return_tensors=\"pt\")\n",
    "    encoded = encoded.to(torch.device(\"cuda\"))\n",
    "    with torch.inference_mode():\n",
    "        generated = model.generate(**encoded, **kwargs)\n",
    "#     print(generated)\n",
    "    for ix in generated.flatten():\n",
    "        print((ix.item(), tokenizer.decode(ix)))\n",
    "    return tokenizer.batch_decode(generated)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b321191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infill(prefix, suffix, **kwargs):\n",
    "    prompt = f\"{FIM_PREFIX}{prefix}{FIM_SUFFIX}{suffix}{FIM_MIDDLE}\"\n",
    "    text = complete(prompt, **kwargs)\n",
    "    if END_OF_TEXT in text:\n",
    "        text = text.split(END_OF_TEXT)[0]\n",
    "    _, middle = text.split(FIM_MIDDLE)\n",
    "    return middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3295d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = '''def ! test_invite_too_man_users(self) -> '''\n",
    "suffix = '''\n",
    "    self.login(self.example_email(\"iago\"))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e26ecd00",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49153, '<fim-prefix>')\n",
      "(563, 'def')\n",
      "(676, '!')\n",
      "(703, ' test')\n",
      "(62, '_')\n",
      "(18970, 'invite')\n",
      "(62, '_')\n",
      "(15267, 'too')\n",
      "(62, '_')\n",
      "(3165, 'man')\n",
      "(62, '_')\n",
      "(3685, 'users')\n",
      "(7, '(')\n",
      "(314, 'self')\n",
      "(8, ')')\n",
      "(1208, ' ->')\n",
      "(207, ' ')\n",
      "(49155, '<fim-suffix>')\n",
      "(258, '\\n   ')\n",
      "(366, ' self')\n",
      "(13, '.')\n",
      "(3157, 'login')\n",
      "(7, '(')\n",
      "(314, 'self')\n",
      "(13, '.')\n",
      "(1887, 'example')\n",
      "(62, '_')\n",
      "(2490, 'email')\n",
      "(372, '(\"')\n",
      "(3990, 'iag')\n",
      "(78, 'o')\n",
      "(1611, '\"))')\n",
      "(49154, '<fim-middle>')\n",
      "(1138, 'None')\n",
      "(25, ':')\n",
      "(258, '\\n   ')\n",
      "(635, ' \"\"\"')\n",
      "(804, 'Test')\n",
      "(954, ' that')\n",
      "(4852, ' inv')\n",
      "(268, 'it')\n",
      "(291, 'ing')\n",
      "(373, ' a')\n",
      "(931, ' user')\n",
      "(669, ' with')\n",
      "(7833, ' too')\n",
      "(7053, ' many')\n",
      "(8696, ' members')\n",
      "(9502, ' fails')\n",
      "(2364, '.\"\"\"')\n",
      "(258, '\\n   ')\n",
      "(366, ' self')\n",
      "(13, '.')\n",
      "(3157, 'login')\n",
      "(7, '(')\n",
      "(314, 'self')\n",
      "(0, '!')\n",
      "(13, '.')\n",
      "(1887, 'example')\n",
      "(62, '_')\n",
      "(2490, 'email')\n",
      "None:\n",
      "    \"\"\"Test that inviting a user with too many members fails.\"\"\"\n",
      "    self.login(self!.example_email\n"
     ]
    }
   ],
   "source": [
    "print(infill(prefix, suffix, max_new_tokens=28, do_sample=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ffbfadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9b630953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(676)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
